{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions for data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the method described to generate train, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the following two paths\n",
    "DATA_DIR = 'input_path'\n",
    "EXP_DIR = 'output_path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'), header=0)\n",
    "train_df['type'] = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_tr_df = pd.read_csv(os.path.join(DATA_DIR, 'validation_tr.csv'), header=0)\n",
    "validation_tr_df['type'] = 'validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tr_df = pd.read_csv(os.path.join(DATA_DIR, 'test_tr.csv'), header=0)\n",
    "test_tr_df['type'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 116676, 116677, 126676, 126677, 136676)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.uid.min(), train_df.uid.max(), validation_tr_df.uid.min(), validation_tr_df.uid.max(),\\\n",
    "test_tr_df.uid.min(), test_tr_df.uid.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = 136676 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tr_df = pd.concat([train_df, validation_tr_df, test_tr_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>sid</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116149</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116149</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116149</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116149</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116149</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      uid  sid   type\n",
       "0  116149    0  train\n",
       "1  116149    1  train\n",
       "2  116149    2  train\n",
       "3  116149    3  train\n",
       "4  116149    4  train"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_te_df = pd.read_csv(os.path.join(DATA_DIR, 'validation_te.csv'), header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>sid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123737</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123737</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120983</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120983</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120983</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      uid  sid\n",
       "0  123737    3\n",
       "1  123737  135\n",
       "2  120983  126\n",
       "3  120983  272\n",
       "4  120983  245"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_te_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_te_df = pd.read_csv(os.path.join(DATA_DIR, 'test_te.csv'), header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>sid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>134677</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134677</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134677</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128041</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128041</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      uid  sid\n",
       "0  134677  239\n",
       "1  134677  504\n",
       "2  134677  367\n",
       "3  128041  125\n",
       "4  128041  235"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_te_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_2_id_df = pd.read_csv(os.path.join(DATA_DIR, 'show2id.txt'), names=['movieId', 'sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items = show_2_id_df.sid.max() + 1\n",
    "num_items\n",
    "availability = np.ones(num_items, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_censored = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_censored:\n",
    "    np.random.seed(0)\n",
    "    cold_start_titles = np.random.choice(pd.unique(test_te_df['sid']), 1000, replace=False)\n",
    "    availability[cold_start_titles] = 0\n",
    "    availability_df = pd.DataFrame({'sid' : np.arange(num_items), 'availability' : availability})\n",
    "    show_2_id_df = pd.merge(show_2_id_df, availability_df, on = 'sid')\n",
    "    all_tr_filtered_df = pd.merge(all_tr_df, show_2_id_df[show_2_id_df.availability == 1], on = 'sid') \n",
    "    print(all_tr_filtered_df.shape, all_tr_df.shape)\n",
    "    print(pd.unique(all_tr_filtered_df.uid).shape, pd.unique(all_tr_df.uid).shape)\n",
    "    pd.unique(all_tr_filtered_df.uid).shape == pd.unique(all_tr_df.uid).shape\n",
    "    all_tr_df = all_tr_filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 : With User-Video Tags; Generative model only for Video History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import sys\n",
    "\n",
    "# pylint: disable=missing-docstring\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import bottleneck as bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_training_data(all_tr_df, num_users, num_items):\n",
    "    rows, cols = all_tr_df['uid'], all_tr_df['sid']\n",
    "    all_tr_mat = sparse.csr_matrix(\n",
    "        (np.ones_like(rows), (rows, cols)),\n",
    "        dtype='float64',\n",
    "        shape=(num_users, num_items))\n",
    "    return all_tr_mat, pd.unique(all_tr_df[all_tr_df.type == 'train'].uid), pd.unique(all_tr_df[all_tr_df.type == 'validation'].uid), pd.unique(all_tr_df[all_tr_df.type == 'test'].uid) \n",
    "\n",
    "def load_vad_te_data(validation_te_df, num_items):\n",
    "    vad_start_idx = validation_te_df['uid'].min()\n",
    "    vad_end_idx = validation_te_df['uid'].max()\n",
    "    rows_te, cols_te = validation_te_df['uid'] - vad_start_idx, validation_te_df['sid']\n",
    "    vad_data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                                 (rows_te, cols_te)),\n",
    "                                dtype='float64', shape=(vad_end_idx - vad_start_idx + 1, num_items))\n",
    "    return vad_data_te, pd.unique(validation_te_df.uid)\n",
    "\n",
    "def get_video_tags_mat(num_items, num_tags, filename):\n",
    "    video_tags_df = pd.read_csv(os.path.join(DATA_DIR, filename), header = 0)\n",
    "    rows, cols = video_tags_df.sid, video_tags_df.genre_index\n",
    "    video_tags_mat = np.zeros((num_items, num_tags))\n",
    "    video_tags_mat[rows, cols] = 1\n",
    "    return video_tags_mat\n",
    "\n",
    "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
    "    '''\n",
    "    normalized discounted cumulative gain@k for binary relevance\n",
    "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
    "    '''\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
    "                       idx_topk_part[:, :k]]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)\n",
    "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
    "    # topk predicted score\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "    # build the discount template\n",
    "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "\n",
    "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
    "                         idx_topk].toarray() * tp).sum(axis=1)\n",
    "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
    "                     for n in heldout_batch.getnnz(axis=1)])\n",
    "    return DCG / IDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tr_mat, train_idxlist, validation_idxlist, test_idxlist =\\\n",
    "load_all_training_data(all_tr_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136677, 20108) (116677,) (10000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(all_tr_mat.shape,train_idxlist.shape, validation_idxlist.shape, test_idxlist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_data_te, _ = load_vad_te_data(validation_te_df, num_items)\n",
    "vad_start_index = validation_idxlist.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 116677\n"
     ]
    }
   ],
   "source": [
    "N_validation = validation_idxlist.shape[0]\n",
    "print(N_validation, vad_start_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_te, _ = load_vad_te_data(test_te_df, num_items)\n",
    "test_start_index = test_idxlist.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20108, 137), 137)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Genre Year Matrix\n",
    "num_tags = pd.read_csv(os.path.join(DATA_DIR, 'genreyear2id.csv'), names=['genre', 'genre_index']).shape[0]\n",
    "video_tags_mat = get_video_tags_mat(num_items, num_tags, 'movies_genres_year.csv')\n",
    "video_tags_mat.shape, num_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tags_per_video = video_tags_mat.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 2., 3., ..., 2., 3., 2.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tags_per_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tags_per_video[num_tags_per_video == 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 2., 3., ..., 2., 3., 2.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tags_per_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadata_array = video_tags_mat / (num_tags_per_video[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20108, 137)\n",
      "137\n"
     ]
    }
   ],
   "source": [
    "print(video_metadata_array.shape)\n",
    "print(num_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(object):\n",
    "    def __init__(self,\n",
    "                 num_users,\n",
    "                 num_items,\n",
    "                 num_tags,\n",
    "                 num_factors,\n",
    "                 var_prior,\n",
    "                 video_metadata_array,\n",
    "                 availability_mask,\n",
    "                 model_variational,\n",
    "                 model_censored,\n",
    "                 model_user_tags,\n",
    "                 model_video_tags):\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_tags = num_tags\n",
    "        self.num_factors = num_factors\n",
    "        self.var_prior = var_prior\n",
    "        self.model_variational = model_variational\n",
    "        self.model_user_tags = model_user_tags\n",
    "        self.model_video_tags = model_video_tags\n",
    "        self.model_censored = model_censored\n",
    "        self.video_metadata_array_const = tf.constant(video_metadata_array, dtype = tf.float32)\n",
    "        self.availability_mask = tf.constant(availability_mask, dtype = tf.float32, shape=[1, num_items])\n",
    "        self.construct_placeholders()\n",
    "        \n",
    "    def construct_placeholders(self):\n",
    "        self.users_ph = tf.placeholder(dtype=tf.int32, shape=[None])\n",
    "        self.played_videos_ph = tf.placeholder(dtype=tf.float32, shape=[None, self.num_items])\n",
    "        if self.model_user_tags:\n",
    "            self.played_tags_ph = tf.placeholder(dtype=tf.float32, shape=[None, self.num_tags])\n",
    "    \n",
    "    def construct_model_variables(self):\n",
    "        self.Mu_Zu = tf.Variable(dtype=tf.float32,\n",
    "                            initial_value=tf.random_normal(shape=[self.num_users, self.num_factors]), \n",
    "                            name = 'mean_latent_factors_zu')\n",
    "        self.lsdev_Zu = tf.Variable(dtype=tf.float32,\n",
    "                               initial_value=tf.random_normal(shape=[self.num_users, 1]), name='lsdev_Zu')\n",
    "\n",
    "        self.Mu_Zv = tf.Variable(dtype=tf.float32,\n",
    "                                 initial_value=tf.random_normal(shape=[self.num_items, self.num_factors]),\n",
    "                                 name = 'mean_latent_factors_zv')\n",
    "        \n",
    "        self.Mu_Zt = tf.Variable(dtype=tf.float32,\n",
    "                            initial_value=tf.random_normal(shape=[self.num_tags, self.num_factors]),\n",
    "                            name = 'mean_latent_factors_zt')\n",
    "        \n",
    "        \n",
    "    def compute_kl_div(self, lsdev_Zu_batch, Mu_Zu_batch):\n",
    "        sdev_Zu_batch = tf.exp(lsdev_Zu_batch)\n",
    "        comp1 = num_factors * (0.5 * np.log(self.var_prior) - lsdev_Zu_batch)\n",
    "        comp2 = (num_factors / (2 * self.var_prior)) * (tf.pow(sdev_Zu_batch, 2))\n",
    "        comp3 = (1.0 / (2 * self.var_prior)) * tf.reduce_sum(tf.pow(Mu_Zu_batch, 2), axis=1, keep_dims = True)\n",
    "        comp4 = (self.num_factors / 2.0)\n",
    "\n",
    "        return comp1 + comp2 + comp3 - comp4\n",
    "        \n",
    "    def construct_graph(self):\n",
    "        self.construct_model_variables()\n",
    "        \n",
    "        Mu_Zu_batch = tf.gather(self.Mu_Zu, self.users_ph)\n",
    "        lsdev_Zu_batch = tf.gather(self.lsdev_Zu, self.users_ph)\n",
    "        Eps_u_ph = tf.random_normal(shape = [tf.size(self.users_ph), self.num_factors],\n",
    "                                    mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=\"eps\")\n",
    "        if self.model_variational:\n",
    "            print('modeling variational, adding noise ...')\n",
    "            Zu_batch = Mu_Zu_batch + Eps_u_ph * tf.exp(lsdev_Zu_batch)\n",
    "        else:\n",
    "            print('modeling non-variational, Zu_batch = Mu_Zu_batch')\n",
    "            Zu_batch = Mu_Zu_batch\n",
    "\n",
    "        if self.model_user_tags and self.model_video_tags:\n",
    "            print('modeling user and video tags ...')\n",
    "            Mu_Zv_hat = tf.matmul(self.video_metadata_array_const, self.Mu_Zt)\n",
    "            Mu_Zu_tag_batch = tf.matmul(self.played_tags_ph, self.Mu_Zt)\n",
    "            batch_logits = tf.matmul(Zu_batch + Mu_Zu_tag_batch, self.Mu_Zv + Mu_Zv_hat, transpose_b=True)\n",
    "            batch_logits_validation = tf.matmul(Mu_Zu_batch + Mu_Zu_tag_batch, self.Mu_Zv + Mu_Zv_hat, transpose_b=True)\n",
    "        if not self.model_user_tags and self.model_video_tags:\n",
    "            print('modeling video tags ...')\n",
    "            Mu_Zv_hat = tf.matmul(self.video_metadata_array_const, self.Mu_Zt)\n",
    "            batch_logits = tf.matmul(Zu_batch, self.Mu_Zv + Mu_Zv_hat, transpose_b=True)\n",
    "            batch_logits_validation = tf.matmul(Mu_Zu_batch, self.Mu_Zv + Mu_Zv_hat, transpose_b=True)\n",
    "        if not self.model_user_tags and not self.model_video_tags:\n",
    "            print('modeling no tags ...')\n",
    "            batch_logits = tf.matmul(Zu_batch, self.Mu_Zv, transpose_b=True)\n",
    "            batch_logits_validation = tf.matmul(Mu_Zu_batch, self.Mu_Zv, transpose_b=True)\n",
    "        if self.model_censored:\n",
    "            print('modeling censored...')\n",
    "            max_logits = tf.reduce_max(batch_logits, axis=1, keep_dims=True)\n",
    "            logsum_exp_masked = max_logits +\\\n",
    "            tf.log(tf.reduce_sum(self.availability_mask * tf.exp(batch_logits - max_logits), axis=1, keep_dims=True) + 1e-8)\n",
    "            log_softmax = batch_logits - logsum_exp_masked\n",
    "        else:\n",
    "            print('modeling non-censored')\n",
    "            log_softmax = tf.nn.log_softmax(batch_logits)\n",
    "        \n",
    "        num_items_per_document = tf.reduce_sum(self.played_videos_ph, axis=1, keep_dims=True)\n",
    "        \n",
    "        batch_conditional_log_likelihood = tf.reduce_sum(self.played_videos_ph * log_softmax, axis = 1, keep_dims=True)\n",
    "        if model_variational:\n",
    "            print('computing elbo')\n",
    "            batch_kl_div = self.compute_kl_div(lsdev_Zu_batch, Mu_Zu_batch)\n",
    "            batch_elbo = (1.0 / num_items_per_document) * (batch_conditional_log_likelihood - batch_kl_div)\n",
    "        else:\n",
    "            print('only using likelihood')\n",
    "\n",
    "            batch_elbo = ((1.0 / num_items_per_document) * batch_conditional_log_likelihood)\n",
    "        \n",
    "        avg_loss = -1 * tf.reduce_mean(batch_elbo) + reg * (tf.nn.l2_loss(self.Mu_Zv) +\n",
    "                                                            tf.nn.l2_loss(self.Mu_Zt))\n",
    "        if not self.model_variational:\n",
    "            print('using l2-loss on Mu_Zu_batch')\n",
    "            avg_loss += reg * tf.nn.l2_loss(Mu_Zu_batch)\n",
    "        \n",
    "        return batch_logits, batch_logits_validation, log_softmax, avg_loss, batch_conditional_log_likelihood,  num_items_per_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_prior = 1.0\n",
    "lr = 4e-3\n",
    "reg = 1e-9\n",
    "num_factors = 100\n",
    "batch_size = 1000\n",
    "num_epochs = 1000\n",
    "model_video_tags = False\n",
    "model_user_tags = False\n",
    "model_variational = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "heldout_idxlist = test_idxlist\n",
    "heldout_start_index = test_start_index\n",
    "heldout_data_te = test_data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment name : censored-False-variational-False-testmetrics-user=id-tags-False-video=id-tags-False-learningrate=0.004-regularization=1e-09-numfactors=100-prior_var-1.0-epochs-1000-attempt=8\n",
      "output dir : /data/ml20m/ml-20m/exp20181002-final\n"
     ]
    }
   ],
   "source": [
    "'''logging info'''\n",
    "attempt = 8\n",
    "experiment_name = 'censored-{model_censored}-variational-{model_variational}-testmetrics-user=id-tags-{model_user_tags}-video=id-tags-{model_video_tags}-learningrate={lr}-regularization={reg}-numfactors={num_factors}-prior_var-{prior_var}-epochs-{epochs}-attempt={attempt}'\\\n",
    ".format(model_censored=model_censored,model_user_tags=model_user_tags, model_video_tags=model_video_tags,\n",
    "        lr=lr, reg=reg, num_factors=num_factors, attempt=attempt, prior_var = var_prior, epochs = num_epochs, model_variational = model_variational)\n",
    "\n",
    "print('experiment name :', experiment_name)\n",
    "print('output dir :', EXP_DIR)\n",
    "\n",
    "!mkdir -p {os.path.join(EXP_DIR, 'logs', experiment_name)}\n",
    "!mkdir -p {os.path.join(EXP_DIR, 'tensorflow_output', experiment_name)}\n",
    "!mkdir -p {os.path.join(EXP_DIR, 'tensorflow_models', experiment_name)}\n",
    "\n",
    "output_line_template = '{epoch_ind},ndcg,{ndcg_mean}+/-{ndcg_se},batch_loss,{batch_loss}'\n",
    "tf.reset_default_graph()\n",
    "fw = open(os.path.join(EXP_DIR, 'logs', experiment_name,'_logs.txt'), 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modeling non-variational, Zu_batch = Mu_Zu_batch\n",
      "modeling no tags ...\n",
      "only using likelihood\n",
      "using l2-loss on Mu_Zu_batch\n",
      "writing out model with ndcg:  0.0020123824366537015  better than best ndcg so far:  -1000\n",
      "0,ndcg,0.00201238243665+/-0.000,batch_loss,39.346\n",
      "writing out model with ndcg:  0.002296468290578545  better than best ndcg so far:  0.0020123824366537015\n",
      "1,ndcg,0.00229646829058+/-0.000,batch_loss,35.053\n",
      "writing out model with ndcg:  0.0026049899666055914  better than best ndcg so far:  0.002296468290578545\n",
      "2,ndcg,0.00260498996661+/-0.000,batch_loss,31.454\n",
      "writing out model with ndcg:  0.003012113335054301  better than best ndcg so far:  0.0026049899666055914\n",
      "3,ndcg,0.00301211333505+/-0.000,batch_loss,28.332\n",
      "writing out model with ndcg:  0.0035174542357283654  better than best ndcg so far:  0.003012113335054301\n",
      "4,ndcg,0.00351745423573+/-0.000,batch_loss,25.511\n",
      "writing out model with ndcg:  0.004223357383472369  better than best ndcg so far:  0.0035174542357283654\n",
      "5,ndcg,0.00422335738347+/-0.000,batch_loss,22.897\n",
      "writing out model with ndcg:  0.00520592914536235  better than best ndcg so far:  0.004223357383472369\n",
      "6,ndcg,0.00520592914536+/-0.000,batch_loss,20.434\n",
      "writing out model with ndcg:  0.006695803379264399  better than best ndcg so far:  0.00520592914536235\n",
      "7,ndcg,0.00669580337926+/-0.000,batch_loss,18.086\n",
      "writing out model with ndcg:  0.00825437296068136  better than best ndcg so far:  0.006695803379264399\n",
      "8,ndcg,0.00825437296068+/-0.000,batch_loss,15.829\n",
      "writing out model with ndcg:  0.010646514188497776  better than best ndcg so far:  0.00825437296068136\n",
      "9,ndcg,0.0106465141885+/-0.000,batch_loss,13.656\n",
      "writing out model with ndcg:  0.014731391711898368  better than best ndcg so far:  0.010646514188497776\n",
      "10,ndcg,0.0147313917119+/-0.001,batch_loss,11.631\n",
      "writing out model with ndcg:  0.02089742400789685  better than best ndcg so far:  0.014731391711898368\n",
      "11,ndcg,0.0208974240079+/-0.001,batch_loss, 9.920\n",
      "writing out model with ndcg:  0.02785475558932743  better than best ndcg so far:  0.02089742400789685\n",
      "12,ndcg,0.0278547555893+/-0.001,batch_loss, 8.669\n",
      "writing out model with ndcg:  0.03643350262519867  better than best ndcg so far:  0.02785475558932743\n",
      "13,ndcg,0.0364335026252+/-0.001,batch_loss, 7.890\n",
      "writing out model with ndcg:  0.04633020998839776  better than best ndcg so far:  0.03643350262519867\n",
      "14,ndcg,0.0463302099884+/-0.001,batch_loss, 7.453\n",
      "writing out model with ndcg:  0.05672319304547692  better than best ndcg so far:  0.04633020998839776\n",
      "15,ndcg,0.0567231930455+/-0.001,batch_loss, 7.207\n",
      "writing out model with ndcg:  0.06792104108292774  better than best ndcg so far:  0.05672319304547692\n",
      "16,ndcg,0.0679210410829+/-0.001,batch_loss, 7.054\n",
      "writing out model with ndcg:  0.0779113946577929  better than best ndcg so far:  0.06792104108292774\n",
      "17,ndcg,0.0779113946578+/-0.001,batch_loss, 6.945\n",
      "writing out model with ndcg:  0.08807512811311297  better than best ndcg so far:  0.0779113946577929\n",
      "18,ndcg,0.0880751281131+/-0.001,batch_loss, 6.859\n",
      "writing out model with ndcg:  0.09728846092995057  better than best ndcg so far:  0.08807512811311297\n",
      "19,ndcg,0.09728846093+/-0.001,batch_loss, 6.786\n",
      "writing out model with ndcg:  0.10589298352515625  better than best ndcg so far:  0.09728846092995057\n",
      "20,ndcg,0.105892983525+/-0.001,batch_loss, 6.722\n",
      "writing out model with ndcg:  0.11366210580378515  better than best ndcg so far:  0.10589298352515625\n",
      "21,ndcg,0.113662105804+/-0.001,batch_loss, 6.663\n",
      "writing out model with ndcg:  0.12001812680709081  better than best ndcg so far:  0.11366210580378515\n",
      "22,ndcg,0.120018126807+/-0.001,batch_loss, 6.609\n",
      "writing out model with ndcg:  0.12632274960265522  better than best ndcg so far:  0.12001812680709081\n",
      "23,ndcg,0.126322749603+/-0.002,batch_loss, 6.557\n",
      "writing out model with ndcg:  0.1318028745828144  better than best ndcg so far:  0.12632274960265522\n",
      "24,ndcg,0.131802874583+/-0.002,batch_loss, 6.507\n",
      "writing out model with ndcg:  0.13667950096732548  better than best ndcg so far:  0.1318028745828144\n",
      "25,ndcg,0.136679500967+/-0.002,batch_loss, 6.460\n",
      "writing out model with ndcg:  0.1411293716451086  better than best ndcg so far:  0.13667950096732548\n",
      "26,ndcg,0.141129371645+/-0.002,batch_loss, 6.414\n",
      "writing out model with ndcg:  0.14521532232204332  better than best ndcg so far:  0.1411293716451086\n",
      "27,ndcg,0.145215322322+/-0.002,batch_loss, 6.368\n",
      "writing out model with ndcg:  0.1486476296531029  better than best ndcg so far:  0.14521532232204332\n",
      "28,ndcg,0.148647629653+/-0.002,batch_loss, 6.325\n",
      "writing out model with ndcg:  0.1519767107555556  better than best ndcg so far:  0.1486476296531029\n",
      "29,ndcg,0.151976710756+/-0.002,batch_loss, 6.283\n",
      "writing out model with ndcg:  0.1544211177807513  better than best ndcg so far:  0.1519767107555556\n",
      "30,ndcg,0.154421117781+/-0.002,batch_loss, 6.241\n",
      "writing out model with ndcg:  0.1574956067845794  better than best ndcg so far:  0.1544211177807513\n",
      "31,ndcg,0.157495606785+/-0.002,batch_loss, 6.202\n",
      "writing out model with ndcg:  0.16053026249984026  better than best ndcg so far:  0.1574956067845794\n",
      "32,ndcg,0.1605302625+/-0.002,batch_loss, 6.163\n",
      "writing out model with ndcg:  0.16271086006544902  better than best ndcg so far:  0.16053026249984026\n",
      "33,ndcg,0.162710860065+/-0.002,batch_loss, 6.124\n",
      "writing out model with ndcg:  0.16491886728570807  better than best ndcg so far:  0.16271086006544902\n",
      "34,ndcg,0.164918867286+/-0.002,batch_loss, 6.087\n",
      "writing out model with ndcg:  0.16775227947197419  better than best ndcg so far:  0.16491886728570807\n",
      "35,ndcg,0.167752279472+/-0.002,batch_loss, 6.052\n",
      "writing out model with ndcg:  0.16888086042186068  better than best ndcg so far:  0.16775227947197419\n",
      "36,ndcg,0.168880860422+/-0.002,batch_loss, 6.017\n",
      "writing out model with ndcg:  0.17090659944033226  better than best ndcg so far:  0.16888086042186068\n",
      "37,ndcg,0.17090659944+/-0.002,batch_loss, 5.984\n",
      "writing out model with ndcg:  0.17212299785705815  better than best ndcg so far:  0.17090659944033226\n",
      "38,ndcg,0.172122997857+/-0.002,batch_loss, 5.953\n",
      "writing out model with ndcg:  0.1735338853375716  better than best ndcg so far:  0.17212299785705815\n",
      "39,ndcg,0.173533885338+/-0.002,batch_loss, 5.922\n",
      "writing out model with ndcg:  0.1746249205299263  better than best ndcg so far:  0.1735338853375716\n",
      "40,ndcg,0.17462492053+/-0.002,batch_loss, 5.891\n",
      "writing out model with ndcg:  0.1761897542308834  better than best ndcg so far:  0.1746249205299263\n",
      "41,ndcg,0.176189754231+/-0.002,batch_loss, 5.860\n",
      "writing out model with ndcg:  0.17651621337387483  better than best ndcg so far:  0.1761897542308834\n",
      "42,ndcg,0.176516213374+/-0.002,batch_loss, 5.831\n",
      "writing out model with ndcg:  0.17784945675435954  better than best ndcg so far:  0.17651621337387483\n",
      "43,ndcg,0.177849456754+/-0.002,batch_loss, 5.801\n",
      "writing out model with ndcg:  0.17835610586915124  better than best ndcg so far:  0.17784945675435954\n",
      "44,ndcg,0.178356105869+/-0.002,batch_loss, 5.771\n",
      "writing out model with ndcg:  0.17908954606905608  better than best ndcg so far:  0.17835610586915124\n",
      "45,ndcg,0.179089546069+/-0.002,batch_loss, 5.743\n",
      "writing out model with ndcg:  0.18050165967416307  better than best ndcg so far:  0.17908954606905608\n",
      "46,ndcg,0.180501659674+/-0.002,batch_loss, 5.713\n",
      "writing out model with ndcg:  0.18104262039540225  better than best ndcg so far:  0.18050165967416307\n",
      "47,ndcg,0.181042620395+/-0.002,batch_loss, 5.685\n",
      "writing out model with ndcg:  0.1815534776480178  better than best ndcg so far:  0.18104262039540225\n",
      "48,ndcg,0.181553477648+/-0.002,batch_loss, 5.657\n",
      "writing out model with ndcg:  0.18262495343310076  better than best ndcg so far:  0.1815534776480178\n",
      "49,ndcg,0.182624953433+/-0.002,batch_loss, 5.630\n",
      "writing out model with ndcg:  0.18411493866281017  better than best ndcg so far:  0.18262495343310076\n",
      "50,ndcg,0.184114938663+/-0.002,batch_loss, 5.603\n",
      "51,ndcg,0.183983910329+/-0.002,batch_loss, 5.576\n",
      "writing out model with ndcg:  0.18533172518373545  better than best ndcg so far:  0.18411493866281017\n",
      "52,ndcg,0.185331725184+/-0.002,batch_loss, 5.550\n",
      "writing out model with ndcg:  0.18628704033899127  better than best ndcg so far:  0.18533172518373545\n",
      "53,ndcg,0.186287040339+/-0.002,batch_loss, 5.523\n",
      "writing out model with ndcg:  0.18688440798401001  better than best ndcg so far:  0.18628704033899127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54,ndcg,0.186884407984+/-0.002,batch_loss, 5.498\n",
      "writing out model with ndcg:  0.18742830146044037  better than best ndcg so far:  0.18688440798401001\n",
      "55,ndcg,0.18742830146+/-0.002,batch_loss, 5.472\n",
      "writing out model with ndcg:  0.18828833188806096  better than best ndcg so far:  0.18742830146044037\n",
      "56,ndcg,0.188288331888+/-0.002,batch_loss, 5.447\n",
      "writing out model with ndcg:  0.1888381697152494  better than best ndcg so far:  0.18828833188806096\n",
      "57,ndcg,0.188838169715+/-0.002,batch_loss, 5.422\n",
      "writing out model with ndcg:  0.18964373010554128  better than best ndcg so far:  0.1888381697152494\n",
      "58,ndcg,0.189643730106+/-0.002,batch_loss, 5.397\n",
      "writing out model with ndcg:  0.18975185023882934  better than best ndcg so far:  0.18964373010554128\n",
      "59,ndcg,0.189751850239+/-0.002,batch_loss, 5.372\n",
      "writing out model with ndcg:  0.19059810873975452  better than best ndcg so far:  0.18975185023882934\n",
      "60,ndcg,0.19059810874+/-0.002,batch_loss, 5.348\n",
      "writing out model with ndcg:  0.19106844803093026  better than best ndcg so far:  0.19059810873975452\n",
      "61,ndcg,0.191068448031+/-0.002,batch_loss, 5.324\n",
      "writing out model with ndcg:  0.19175544210731035  better than best ndcg so far:  0.19106844803093026\n",
      "62,ndcg,0.191755442107+/-0.002,batch_loss, 5.300\n",
      "writing out model with ndcg:  0.19278246078042607  better than best ndcg so far:  0.19175544210731035\n",
      "63,ndcg,0.19278246078+/-0.002,batch_loss, 5.277\n",
      "writing out model with ndcg:  0.1930710248598025  better than best ndcg so far:  0.19278246078042607\n",
      "64,ndcg,0.19307102486+/-0.002,batch_loss, 5.254\n",
      "writing out model with ndcg:  0.19369535912731073  better than best ndcg so far:  0.1930710248598025\n",
      "65,ndcg,0.193695359127+/-0.002,batch_loss, 5.231\n",
      "writing out model with ndcg:  0.19399095952641066  better than best ndcg so far:  0.19369535912731073\n",
      "66,ndcg,0.193990959526+/-0.002,batch_loss, 5.209\n",
      "writing out model with ndcg:  0.1943080667412067  better than best ndcg so far:  0.19399095952641066\n",
      "67,ndcg,0.194308066741+/-0.002,batch_loss, 5.187\n",
      "writing out model with ndcg:  0.1955760780543657  better than best ndcg so far:  0.1943080667412067\n",
      "68,ndcg,0.195576078054+/-0.002,batch_loss, 5.166\n",
      "69,ndcg,0.195541068648+/-0.002,batch_loss, 5.145\n",
      "writing out model with ndcg:  0.19592421368587162  better than best ndcg so far:  0.1955760780543657\n",
      "70,ndcg,0.195924213686+/-0.002,batch_loss, 5.124\n",
      "writing out model with ndcg:  0.1965295439819985  better than best ndcg so far:  0.19592421368587162\n",
      "71,ndcg,0.196529543982+/-0.002,batch_loss, 5.104\n",
      "writing out model with ndcg:  0.1972085240035155  better than best ndcg so far:  0.1965295439819985\n",
      "72,ndcg,0.197208524004+/-0.002,batch_loss, 5.084\n",
      "writing out model with ndcg:  0.19725000609785232  better than best ndcg so far:  0.1972085240035155\n",
      "73,ndcg,0.197250006098+/-0.002,batch_loss, 5.064\n",
      "writing out model with ndcg:  0.19788023406164337  better than best ndcg so far:  0.19725000609785232\n",
      "74,ndcg,0.197880234062+/-0.002,batch_loss, 5.045\n",
      "writing out model with ndcg:  0.19831796370268778  better than best ndcg so far:  0.19788023406164337\n",
      "75,ndcg,0.198317963703+/-0.002,batch_loss, 5.027\n",
      "writing out model with ndcg:  0.19892794914382572  better than best ndcg so far:  0.19831796370268778\n",
      "76,ndcg,0.198927949144+/-0.002,batch_loss, 5.008\n",
      "writing out model with ndcg:  0.19946354040599004  better than best ndcg so far:  0.19892794914382572\n",
      "77,ndcg,0.199463540406+/-0.002,batch_loss, 4.991\n",
      "writing out model with ndcg:  0.20028761147980387  better than best ndcg so far:  0.19946354040599004\n",
      "78,ndcg,0.20028761148+/-0.002,batch_loss, 4.973\n",
      "writing out model with ndcg:  0.20056405283348486  better than best ndcg so far:  0.20028761147980387\n",
      "79,ndcg,0.200564052833+/-0.002,batch_loss, 4.956\n",
      "writing out model with ndcg:  0.20152847967142673  better than best ndcg so far:  0.20056405283348486\n",
      "80,ndcg,0.201528479671+/-0.002,batch_loss, 4.939\n",
      "writing out model with ndcg:  0.20203605231910698  better than best ndcg so far:  0.20152847967142673\n",
      "81,ndcg,0.202036052319+/-0.002,batch_loss, 4.923\n",
      "writing out model with ndcg:  0.20231583203265896  better than best ndcg so far:  0.20203605231910698\n",
      "82,ndcg,0.202315832033+/-0.002,batch_loss, 4.907\n",
      "writing out model with ndcg:  0.20295003358614241  better than best ndcg so far:  0.20231583203265896\n",
      "83,ndcg,0.202950033586+/-0.002,batch_loss, 4.892\n",
      "writing out model with ndcg:  0.20374232819017854  better than best ndcg so far:  0.20295003358614241\n",
      "84,ndcg,0.20374232819+/-0.002,batch_loss, 4.878\n",
      "writing out model with ndcg:  0.2038774424164924  better than best ndcg so far:  0.20374232819017854\n",
      "85,ndcg,0.203877442416+/-0.002,batch_loss, 4.863\n",
      "writing out model with ndcg:  0.20463762032329497  better than best ndcg so far:  0.2038774424164924\n",
      "86,ndcg,0.204637620323+/-0.002,batch_loss, 4.849\n",
      "writing out model with ndcg:  0.20476780478687745  better than best ndcg so far:  0.20463762032329497\n",
      "87,ndcg,0.204767804787+/-0.002,batch_loss, 4.835\n",
      "writing out model with ndcg:  0.20611741924090862  better than best ndcg so far:  0.20476780478687745\n",
      "88,ndcg,0.206117419241+/-0.002,batch_loss, 4.821\n",
      "writing out model with ndcg:  0.20652818096816494  better than best ndcg so far:  0.20611741924090862\n",
      "89,ndcg,0.206528180968+/-0.002,batch_loss, 4.808\n",
      "writing out model with ndcg:  0.20719469930110604  better than best ndcg so far:  0.20652818096816494\n",
      "90,ndcg,0.207194699301+/-0.002,batch_loss, 4.795\n",
      "91,ndcg,0.206984958468+/-0.002,batch_loss, 4.783\n",
      "writing out model with ndcg:  0.20846002903629332  better than best ndcg so far:  0.20719469930110604\n",
      "92,ndcg,0.208460029036+/-0.002,batch_loss, 4.771\n",
      "writing out model with ndcg:  0.2086441089197553  better than best ndcg so far:  0.20846002903629332\n",
      "93,ndcg,0.20864410892+/-0.002,batch_loss, 4.760\n",
      "writing out model with ndcg:  0.20930907698140364  better than best ndcg so far:  0.2086441089197553\n",
      "94,ndcg,0.209309076981+/-0.002,batch_loss, 4.749\n",
      "writing out model with ndcg:  0.2099019856359708  better than best ndcg so far:  0.20930907698140364\n",
      "95,ndcg,0.209901985636+/-0.002,batch_loss, 4.737\n",
      "writing out model with ndcg:  0.21043115438630672  better than best ndcg so far:  0.2099019856359708\n",
      "96,ndcg,0.210431154386+/-0.002,batch_loss, 4.726\n",
      "writing out model with ndcg:  0.21070681104134883  better than best ndcg so far:  0.21043115438630672\n",
      "97,ndcg,0.210706811041+/-0.002,batch_loss, 4.716\n",
      "writing out model with ndcg:  0.21220450283826475  better than best ndcg so far:  0.21070681104134883\n",
      "98,ndcg,0.212204502838+/-0.002,batch_loss, 4.706\n",
      "99,ndcg,0.211737035379+/-0.002,batch_loss, 4.696\n",
      "writing out model with ndcg:  0.21230849876480776  better than best ndcg so far:  0.21220450283826475\n",
      "100,ndcg,0.212308498765+/-0.002,batch_loss, 4.686\n",
      "writing out model with ndcg:  0.2131780546320767  better than best ndcg so far:  0.21230849876480776\n",
      "101,ndcg,0.213178054632+/-0.002,batch_loss, 4.677\n",
      "writing out model with ndcg:  0.2134600003483954  better than best ndcg so far:  0.2131780546320767\n",
      "102,ndcg,0.213460000348+/-0.002,batch_loss, 4.668\n",
      "writing out model with ndcg:  0.21456696278746448  better than best ndcg so far:  0.2134600003483954\n",
      "103,ndcg,0.214566962787+/-0.002,batch_loss, 4.659\n",
      "writing out model with ndcg:  0.2152828130100645  better than best ndcg so far:  0.21456696278746448\n",
      "104,ndcg,0.21528281301+/-0.002,batch_loss, 4.651\n",
      "writing out model with ndcg:  0.21557390052409986  better than best ndcg so far:  0.2152828130100645\n",
      "105,ndcg,0.215573900524+/-0.002,batch_loss, 4.642\n",
      "writing out model with ndcg:  0.21606988978657632  better than best ndcg so far:  0.21557390052409986\n",
      "106,ndcg,0.216069889787+/-0.002,batch_loss, 4.634\n",
      "writing out model with ndcg:  0.21700718504288383  better than best ndcg so far:  0.21606988978657632\n",
      "107,ndcg,0.217007185043+/-0.002,batch_loss, 4.626\n",
      "108,ndcg,0.216904677181+/-0.002,batch_loss, 4.618\n",
      "writing out model with ndcg:  0.21839947409360583  better than best ndcg so far:  0.21700718504288383\n",
      "109,ndcg,0.218399474094+/-0.002,batch_loss, 4.611\n",
      "110,ndcg,0.218350845298+/-0.002,batch_loss, 4.604\n",
      "writing out model with ndcg:  0.21900766996274496  better than best ndcg so far:  0.21839947409360583\n",
      "111,ndcg,0.219007669963+/-0.002,batch_loss, 4.597\n",
      "writing out model with ndcg:  0.2202317519638169  better than best ndcg so far:  0.21900766996274496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112,ndcg,0.220231751964+/-0.002,batch_loss, 4.590\n",
      "writing out model with ndcg:  0.2205663405648123  better than best ndcg so far:  0.2202317519638169\n",
      "113,ndcg,0.220566340565+/-0.002,batch_loss, 4.583\n",
      "writing out model with ndcg:  0.22099160146242244  better than best ndcg so far:  0.2205663405648123\n",
      "114,ndcg,0.220991601462+/-0.002,batch_loss, 4.577\n",
      "writing out model with ndcg:  0.22182425227395897  better than best ndcg so far:  0.22099160146242244\n",
      "115,ndcg,0.221824252274+/-0.002,batch_loss, 4.570\n",
      "writing out model with ndcg:  0.22226912390317202  better than best ndcg so far:  0.22182425227395897\n",
      "116,ndcg,0.222269123903+/-0.002,batch_loss, 4.564\n",
      "writing out model with ndcg:  0.22303551802862157  better than best ndcg so far:  0.22226912390317202\n",
      "117,ndcg,0.223035518029+/-0.002,batch_loss, 4.558\n",
      "writing out model with ndcg:  0.2235768190246872  better than best ndcg so far:  0.22303551802862157\n",
      "118,ndcg,0.223576819025+/-0.002,batch_loss, 4.552\n",
      "writing out model with ndcg:  0.22425655435670205  better than best ndcg so far:  0.2235768190246872\n",
      "119,ndcg,0.224256554357+/-0.002,batch_loss, 4.546\n",
      "writing out model with ndcg:  0.22504483459110178  better than best ndcg so far:  0.22425655435670205\n",
      "120,ndcg,0.225044834591+/-0.002,batch_loss, 4.540\n",
      "writing out model with ndcg:  0.22599898309575564  better than best ndcg so far:  0.22504483459110178\n",
      "121,ndcg,0.225998983096+/-0.002,batch_loss, 4.535\n",
      "122,ndcg,0.225778364456+/-0.002,batch_loss, 4.530\n",
      "writing out model with ndcg:  0.22679660901907722  better than best ndcg so far:  0.22599898309575564\n",
      "123,ndcg,0.226796609019+/-0.002,batch_loss, 4.525\n",
      "writing out model with ndcg:  0.22768420656575772  better than best ndcg so far:  0.22679660901907722\n",
      "124,ndcg,0.227684206566+/-0.002,batch_loss, 4.520\n",
      "writing out model with ndcg:  0.22805350329647514  better than best ndcg so far:  0.22768420656575772\n",
      "125,ndcg,0.228053503296+/-0.002,batch_loss, 4.515\n",
      "writing out model with ndcg:  0.22881594185356688  better than best ndcg so far:  0.22805350329647514\n",
      "126,ndcg,0.228815941854+/-0.002,batch_loss, 4.510\n",
      "writing out model with ndcg:  0.22953284859424908  better than best ndcg so far:  0.22881594185356688\n",
      "127,ndcg,0.229532848594+/-0.002,batch_loss, 4.506\n",
      "writing out model with ndcg:  0.229862408110072  better than best ndcg so far:  0.22953284859424908\n",
      "128,ndcg,0.22986240811+/-0.002,batch_loss, 4.501\n",
      "writing out model with ndcg:  0.23083874897050383  better than best ndcg so far:  0.229862408110072\n",
      "129,ndcg,0.230838748971+/-0.002,batch_loss, 4.497\n",
      "writing out model with ndcg:  0.23127464906309528  better than best ndcg so far:  0.23083874897050383\n",
      "130,ndcg,0.231274649063+/-0.002,batch_loss, 4.492\n",
      "writing out model with ndcg:  0.23195541919456328  better than best ndcg so far:  0.23127464906309528\n",
      "131,ndcg,0.231955419195+/-0.002,batch_loss, 4.488\n",
      "writing out model with ndcg:  0.23230715592476175  better than best ndcg so far:  0.23195541919456328\n",
      "132,ndcg,0.232307155925+/-0.002,batch_loss, 4.484\n",
      "writing out model with ndcg:  0.23328178934668023  better than best ndcg so far:  0.23230715592476175\n",
      "133,ndcg,0.233281789347+/-0.002,batch_loss, 4.480\n",
      "writing out model with ndcg:  0.2340571740999121  better than best ndcg so far:  0.23328178934668023\n",
      "134,ndcg,0.2340571741+/-0.002,batch_loss, 4.476\n",
      "writing out model with ndcg:  0.23463528446025234  better than best ndcg so far:  0.2340571740999121\n",
      "135,ndcg,0.23463528446+/-0.002,batch_loss, 4.473\n",
      "writing out model with ndcg:  0.23493568888323826  better than best ndcg so far:  0.23463528446025234\n",
      "136,ndcg,0.234935688883+/-0.002,batch_loss, 4.469\n",
      "writing out model with ndcg:  0.2359306706215625  better than best ndcg so far:  0.23493568888323826\n",
      "137,ndcg,0.235930670622+/-0.002,batch_loss, 4.466\n",
      "writing out model with ndcg:  0.2364659538589952  better than best ndcg so far:  0.2359306706215625\n",
      "138,ndcg,0.236465953859+/-0.002,batch_loss, 4.462\n",
      "writing out model with ndcg:  0.23702422443853444  better than best ndcg so far:  0.2364659538589952\n",
      "139,ndcg,0.237024224439+/-0.002,batch_loss, 4.458\n",
      "writing out model with ndcg:  0.23778865721332676  better than best ndcg so far:  0.23702422443853444\n",
      "140,ndcg,0.237788657213+/-0.002,batch_loss, 4.455\n",
      "writing out model with ndcg:  0.2385323710706467  better than best ndcg so far:  0.23778865721332676\n",
      "141,ndcg,0.238532371071+/-0.002,batch_loss, 4.452\n",
      "writing out model with ndcg:  0.2389391060198694  better than best ndcg so far:  0.2385323710706467\n",
      "142,ndcg,0.23893910602+/-0.002,batch_loss, 4.449\n",
      "writing out model with ndcg:  0.24016820534160507  better than best ndcg so far:  0.2389391060198694\n",
      "143,ndcg,0.240168205342+/-0.002,batch_loss, 4.446\n",
      "144,ndcg,0.239951099471+/-0.002,batch_loss, 4.443\n",
      "writing out model with ndcg:  0.2412664813558954  better than best ndcg so far:  0.24016820534160507\n",
      "145,ndcg,0.241266481356+/-0.002,batch_loss, 4.440\n",
      "writing out model with ndcg:  0.24163152363516632  better than best ndcg so far:  0.2412664813558954\n",
      "146,ndcg,0.241631523635+/-0.002,batch_loss, 4.437\n",
      "writing out model with ndcg:  0.2420678186387985  better than best ndcg so far:  0.24163152363516632\n",
      "147,ndcg,0.242067818639+/-0.002,batch_loss, 4.434\n",
      "writing out model with ndcg:  0.24225798353782674  better than best ndcg so far:  0.2420678186387985\n",
      "148,ndcg,0.242257983538+/-0.002,batch_loss, 4.431\n",
      "writing out model with ndcg:  0.2434267897717984  better than best ndcg so far:  0.24225798353782674\n",
      "149,ndcg,0.243426789772+/-0.002,batch_loss, 4.429\n",
      "writing out model with ndcg:  0.24413434588794672  better than best ndcg so far:  0.2434267897717984\n",
      "150,ndcg,0.244134345888+/-0.002,batch_loss, 4.427\n",
      "writing out model with ndcg:  0.24491317477464963  better than best ndcg so far:  0.24413434588794672\n",
      "151,ndcg,0.244913174775+/-0.002,batch_loss, 4.424\n",
      "writing out model with ndcg:  0.24532998416772853  better than best ndcg so far:  0.24491317477464963\n",
      "152,ndcg,0.245329984168+/-0.002,batch_loss, 4.421\n",
      "writing out model with ndcg:  0.24534010385033375  better than best ndcg so far:  0.24532998416772853\n",
      "153,ndcg,0.24534010385+/-0.002,batch_loss, 4.419\n",
      "writing out model with ndcg:  0.24678386348792414  better than best ndcg so far:  0.24534010385033375\n",
      "154,ndcg,0.246783863488+/-0.002,batch_loss, 4.416\n",
      "writing out model with ndcg:  0.24712219206171668  better than best ndcg so far:  0.24678386348792414\n",
      "155,ndcg,0.247122192062+/-0.002,batch_loss, 4.414\n",
      "writing out model with ndcg:  0.24816046932509125  better than best ndcg so far:  0.24712219206171668\n",
      "156,ndcg,0.248160469325+/-0.002,batch_loss, 4.412\n",
      "writing out model with ndcg:  0.24863314491843008  better than best ndcg so far:  0.24816046932509125\n",
      "157,ndcg,0.248633144918+/-0.002,batch_loss, 4.410\n",
      "writing out model with ndcg:  0.24916114892877528  better than best ndcg so far:  0.24863314491843008\n",
      "158,ndcg,0.249161148929+/-0.002,batch_loss, 4.407\n",
      "writing out model with ndcg:  0.25010138545739563  better than best ndcg so far:  0.24916114892877528\n",
      "159,ndcg,0.250101385457+/-0.002,batch_loss, 4.406\n",
      "writing out model with ndcg:  0.2505416815957003  better than best ndcg so far:  0.25010138545739563\n",
      "160,ndcg,0.250541681596+/-0.002,batch_loss, 4.403\n",
      "writing out model with ndcg:  0.2512743663723378  better than best ndcg so far:  0.2505416815957003\n",
      "161,ndcg,0.251274366372+/-0.002,batch_loss, 4.401\n",
      "writing out model with ndcg:  0.25159058479517554  better than best ndcg so far:  0.2512743663723378\n",
      "162,ndcg,0.251590584795+/-0.002,batch_loss, 4.399\n",
      "writing out model with ndcg:  0.2518536631094484  better than best ndcg so far:  0.25159058479517554\n",
      "163,ndcg,0.251853663109+/-0.002,batch_loss, 4.397\n",
      "writing out model with ndcg:  0.25280910108151783  better than best ndcg so far:  0.2518536631094484\n",
      "164,ndcg,0.252809101082+/-0.002,batch_loss, 4.395\n",
      "writing out model with ndcg:  0.2542488412832986  better than best ndcg so far:  0.25280910108151783\n",
      "165,ndcg,0.254248841283+/-0.002,batch_loss, 4.393\n",
      "writing out model with ndcg:  0.2549426881776807  better than best ndcg so far:  0.2542488412832986\n",
      "166,ndcg,0.254942688178+/-0.002,batch_loss, 4.392\n",
      "167,ndcg,0.254590915889+/-0.002,batch_loss, 4.390\n",
      "writing out model with ndcg:  0.25527109027906325  better than best ndcg so far:  0.2549426881776807\n",
      "168,ndcg,0.255271090279+/-0.002,batch_loss, 4.388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing out model with ndcg:  0.25630182377314237  better than best ndcg so far:  0.25527109027906325\n",
      "169,ndcg,0.256301823773+/-0.002,batch_loss, 4.387\n",
      "writing out model with ndcg:  0.25644961183156295  better than best ndcg so far:  0.25630182377314237\n",
      "170,ndcg,0.256449611832+/-0.002,batch_loss, 4.385\n",
      "writing out model with ndcg:  0.2577095919211061  better than best ndcg so far:  0.25644961183156295\n",
      "171,ndcg,0.257709591921+/-0.002,batch_loss, 4.383\n",
      "writing out model with ndcg:  0.2584005580973035  better than best ndcg so far:  0.2577095919211061\n",
      "172,ndcg,0.258400558097+/-0.002,batch_loss, 4.381\n",
      "writing out model with ndcg:  0.2592068438787746  better than best ndcg so far:  0.2584005580973035\n",
      "173,ndcg,0.259206843879+/-0.002,batch_loss, 4.380\n",
      "174,ndcg,0.258989745895+/-0.002,batch_loss, 4.379\n",
      "writing out model with ndcg:  0.25965277211764487  better than best ndcg so far:  0.2592068438787746\n",
      "175,ndcg,0.259652772118+/-0.002,batch_loss, 4.377\n",
      "writing out model with ndcg:  0.2604185668483533  better than best ndcg so far:  0.25965277211764487\n",
      "176,ndcg,0.260418566848+/-0.002,batch_loss, 4.375\n",
      "writing out model with ndcg:  0.2612925768047654  better than best ndcg so far:  0.2604185668483533\n",
      "177,ndcg,0.261292576805+/-0.002,batch_loss, 4.374\n",
      "writing out model with ndcg:  0.2615465276756473  better than best ndcg so far:  0.2612925768047654\n",
      "178,ndcg,0.261546527676+/-0.002,batch_loss, 4.372\n",
      "writing out model with ndcg:  0.26156768090796434  better than best ndcg so far:  0.2615465276756473\n",
      "179,ndcg,0.261567680908+/-0.002,batch_loss, 4.371\n",
      "writing out model with ndcg:  0.26244775435349865  better than best ndcg so far:  0.26156768090796434\n",
      "180,ndcg,0.262447754353+/-0.002,batch_loss, 4.370\n",
      "writing out model with ndcg:  0.2639238241367286  better than best ndcg so far:  0.26244775435349865\n",
      "181,ndcg,0.263923824137+/-0.002,batch_loss, 4.368\n",
      "182,ndcg,0.263477219478+/-0.002,batch_loss, 4.367\n",
      "writing out model with ndcg:  0.26456952006373996  better than best ndcg so far:  0.2639238241367286\n",
      "183,ndcg,0.264569520064+/-0.002,batch_loss, 4.366\n",
      "writing out model with ndcg:  0.2650772518293409  better than best ndcg so far:  0.26456952006373996\n",
      "184,ndcg,0.265077251829+/-0.002,batch_loss, 4.365\n",
      "writing out model with ndcg:  0.26560184485278576  better than best ndcg so far:  0.2650772518293409\n",
      "185,ndcg,0.265601844853+/-0.002,batch_loss, 4.363\n",
      "writing out model with ndcg:  0.2664851987432225  better than best ndcg so far:  0.26560184485278576\n",
      "186,ndcg,0.266485198743+/-0.002,batch_loss, 4.362\n",
      "writing out model with ndcg:  0.26709575934156066  better than best ndcg so far:  0.2664851987432225\n",
      "187,ndcg,0.267095759342+/-0.002,batch_loss, 4.361\n",
      "188,ndcg,0.266654129441+/-0.002,batch_loss, 4.360\n",
      "writing out model with ndcg:  0.2678245790062954  better than best ndcg so far:  0.26709575934156066\n",
      "189,ndcg,0.267824579006+/-0.002,batch_loss, 4.358\n",
      "writing out model with ndcg:  0.26826184878665293  better than best ndcg so far:  0.2678245790062954\n",
      "190,ndcg,0.268261848787+/-0.002,batch_loss, 4.357\n",
      "writing out model with ndcg:  0.2693168783926856  better than best ndcg so far:  0.26826184878665293\n",
      "191,ndcg,0.269316878393+/-0.002,batch_loss, 4.356\n",
      "writing out model with ndcg:  0.2698200465397849  better than best ndcg so far:  0.2693168783926856\n",
      "192,ndcg,0.26982004654+/-0.002,batch_loss, 4.355\n",
      "writing out model with ndcg:  0.26982121553508565  better than best ndcg so far:  0.2698200465397849\n",
      "193,ndcg,0.269821215535+/-0.002,batch_loss, 4.354\n",
      "writing out model with ndcg:  0.27034371359777615  better than best ndcg so far:  0.26982121553508565\n",
      "194,ndcg,0.270343713598+/-0.002,batch_loss, 4.353\n",
      "195,ndcg,0.270227184142+/-0.002,batch_loss, 4.351\n",
      "writing out model with ndcg:  0.27105512461214865  better than best ndcg so far:  0.27034371359777615\n",
      "196,ndcg,0.271055124612+/-0.002,batch_loss, 4.350\n",
      "writing out model with ndcg:  0.27217905460408565  better than best ndcg so far:  0.27105512461214865\n",
      "197,ndcg,0.272179054604+/-0.002,batch_loss, 4.350\n",
      "writing out model with ndcg:  0.2724423203696488  better than best ndcg so far:  0.27217905460408565\n",
      "198,ndcg,0.27244232037+/-0.002,batch_loss, 4.348\n",
      "writing out model with ndcg:  0.27290417458584415  better than best ndcg so far:  0.2724423203696488\n",
      "199,ndcg,0.272904174586+/-0.002,batch_loss, 4.348\n",
      "writing out model with ndcg:  0.27355976598479603  better than best ndcg so far:  0.27290417458584415\n",
      "200,ndcg,0.273559765985+/-0.002,batch_loss, 4.347\n",
      "writing out model with ndcg:  0.27402962595287234  better than best ndcg so far:  0.27355976598479603\n",
      "201,ndcg,0.274029625953+/-0.002,batch_loss, 4.346\n",
      "202,ndcg,0.273964273067+/-0.002,batch_loss, 4.345\n",
      "writing out model with ndcg:  0.2750497813929128  better than best ndcg so far:  0.27402962595287234\n",
      "203,ndcg,0.275049781393+/-0.002,batch_loss, 4.343\n",
      "writing out model with ndcg:  0.2751118570930078  better than best ndcg so far:  0.2750497813929128\n",
      "204,ndcg,0.275111857093+/-0.002,batch_loss, 4.343\n",
      "writing out model with ndcg:  0.27591766921254135  better than best ndcg so far:  0.2751118570930078\n",
      "205,ndcg,0.275917669213+/-0.002,batch_loss, 4.342\n",
      "206,ndcg,0.275827379485+/-0.002,batch_loss, 4.341\n",
      "writing out model with ndcg:  0.2771726973899628  better than best ndcg so far:  0.27591766921254135\n",
      "207,ndcg,0.27717269739+/-0.002,batch_loss, 4.340\n",
      "writing out model with ndcg:  0.2773737819082148  better than best ndcg so far:  0.2771726973899628\n",
      "208,ndcg,0.277373781908+/-0.002,batch_loss, 4.340\n",
      "writing out model with ndcg:  0.2778184822518751  better than best ndcg so far:  0.2773737819082148\n",
      "209,ndcg,0.277818482252+/-0.002,batch_loss, 4.338\n",
      "writing out model with ndcg:  0.27837616122345166  better than best ndcg so far:  0.2778184822518751\n",
      "210,ndcg,0.278376161223+/-0.002,batch_loss, 4.338\n",
      "writing out model with ndcg:  0.27918789932047805  better than best ndcg so far:  0.27837616122345166\n",
      "211,ndcg,0.27918789932+/-0.002,batch_loss, 4.337\n",
      "writing out model with ndcg:  0.2793158721909989  better than best ndcg so far:  0.27918789932047805\n",
      "212,ndcg,0.279315872191+/-0.002,batch_loss, 4.336\n",
      "writing out model with ndcg:  0.28022469249076853  better than best ndcg so far:  0.2793158721909989\n",
      "213,ndcg,0.280224692491+/-0.002,batch_loss, 4.335\n",
      "214,ndcg,0.27977547362+/-0.002,batch_loss, 4.335\n",
      "writing out model with ndcg:  0.2812390961094808  better than best ndcg so far:  0.28022469249076853\n",
      "215,ndcg,0.281239096109+/-0.002,batch_loss, 4.334\n",
      "writing out model with ndcg:  0.2813335389497206  better than best ndcg so far:  0.2812390961094808\n",
      "216,ndcg,0.28133353895+/-0.002,batch_loss, 4.332\n",
      "writing out model with ndcg:  0.28145189841229096  better than best ndcg so far:  0.2813335389497206\n",
      "217,ndcg,0.281451898412+/-0.002,batch_loss, 4.332\n",
      "writing out model with ndcg:  0.28207536134635075  better than best ndcg so far:  0.28145189841229096\n",
      "218,ndcg,0.282075361346+/-0.002,batch_loss, 4.332\n",
      "writing out model with ndcg:  0.2826247565222468  better than best ndcg so far:  0.28207536134635075\n",
      "219,ndcg,0.282624756522+/-0.002,batch_loss, 4.331\n",
      "writing out model with ndcg:  0.28313905054318045  better than best ndcg so far:  0.2826247565222468\n",
      "220,ndcg,0.283139050543+/-0.002,batch_loss, 4.330\n",
      "writing out model with ndcg:  0.28363643629194846  better than best ndcg so far:  0.28313905054318045\n",
      "221,ndcg,0.283636436292+/-0.002,batch_loss, 4.329\n",
      "222,ndcg,0.283542848767+/-0.002,batch_loss, 4.328\n",
      "writing out model with ndcg:  0.2842251152262562  better than best ndcg so far:  0.28363643629194846\n",
      "223,ndcg,0.284225115226+/-0.002,batch_loss, 4.328\n",
      "writing out model with ndcg:  0.2848284984475902  better than best ndcg so far:  0.2842251152262562\n",
      "224,ndcg,0.284828498448+/-0.002,batch_loss, 4.327\n",
      "225,ndcg,0.284805824566+/-0.002,batch_loss, 4.326\n",
      "writing out model with ndcg:  0.2859287051996603  better than best ndcg so far:  0.2848284984475902\n",
      "226,ndcg,0.2859287052+/-0.002,batch_loss, 4.326\n",
      "writing out model with ndcg:  0.2864346941044967  better than best ndcg so far:  0.2859287051996603\n",
      "227,ndcg,0.286434694104+/-0.002,batch_loss, 4.325\n",
      "writing out model with ndcg:  0.2864380728574781  better than best ndcg so far:  0.2864346941044967\n",
      "228,ndcg,0.286438072857+/-0.002,batch_loss, 4.324\n",
      "writing out model with ndcg:  0.2872196271930664  better than best ndcg so far:  0.2864380728574781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229,ndcg,0.287219627193+/-0.002,batch_loss, 4.324\n",
      "230,ndcg,0.287081922591+/-0.002,batch_loss, 4.323\n",
      "231,ndcg,0.287115232688+/-0.002,batch_loss, 4.323\n",
      "writing out model with ndcg:  0.2887599522442193  better than best ndcg so far:  0.2872196271930664\n",
      "232,ndcg,0.288759952244+/-0.002,batch_loss, 4.322\n",
      "233,ndcg,0.288473170992+/-0.002,batch_loss, 4.321\n",
      "writing out model with ndcg:  0.2892966755772428  better than best ndcg so far:  0.2887599522442193\n",
      "234,ndcg,0.289296675577+/-0.002,batch_loss, 4.320\n",
      "writing out model with ndcg:  0.28971099386225024  better than best ndcg so far:  0.2892966755772428\n",
      "235,ndcg,0.289710993862+/-0.002,batch_loss, 4.320\n",
      "writing out model with ndcg:  0.28997532850649776  better than best ndcg so far:  0.28971099386225024\n",
      "236,ndcg,0.289975328506+/-0.002,batch_loss, 4.319\n",
      "writing out model with ndcg:  0.2905351140807155  better than best ndcg so far:  0.28997532850649776\n",
      "237,ndcg,0.290535114081+/-0.002,batch_loss, 4.319\n",
      "writing out model with ndcg:  0.2910622213605217  better than best ndcg so far:  0.2905351140807155\n",
      "238,ndcg,0.291062221361+/-0.002,batch_loss, 4.318\n",
      "writing out model with ndcg:  0.2915041754226016  better than best ndcg so far:  0.2910622213605217\n",
      "239,ndcg,0.291504175423+/-0.002,batch_loss, 4.318\n",
      "writing out model with ndcg:  0.29188527580016355  better than best ndcg so far:  0.2915041754226016\n",
      "240,ndcg,0.2918852758+/-0.002,batch_loss, 4.317\n",
      "241,ndcg,0.291432849629+/-0.002,batch_loss, 4.317\n",
      "writing out model with ndcg:  0.29242932480881256  better than best ndcg so far:  0.29188527580016355\n",
      "242,ndcg,0.292429324809+/-0.002,batch_loss, 4.316\n",
      "writing out model with ndcg:  0.29302463082238794  better than best ndcg so far:  0.29242932480881256\n",
      "243,ndcg,0.293024630822+/-0.002,batch_loss, 4.316\n",
      "244,ndcg,0.292620936147+/-0.002,batch_loss, 4.315\n",
      "writing out model with ndcg:  0.2937797546895017  better than best ndcg so far:  0.29302463082238794\n",
      "245,ndcg,0.29377975469+/-0.002,batch_loss, 4.314\n",
      "writing out model with ndcg:  0.2946083804550511  better than best ndcg so far:  0.2937797546895017\n",
      "246,ndcg,0.294608380455+/-0.002,batch_loss, 4.314\n",
      "247,ndcg,0.294520254952+/-0.002,batch_loss, 4.313\n",
      "writing out model with ndcg:  0.2947022928364512  better than best ndcg so far:  0.2946083804550511\n",
      "248,ndcg,0.294702292836+/-0.002,batch_loss, 4.313\n",
      "writing out model with ndcg:  0.2954590275744316  better than best ndcg so far:  0.2947022928364512\n",
      "249,ndcg,0.295459027574+/-0.002,batch_loss, 4.312\n",
      "writing out model with ndcg:  0.2960634575846971  better than best ndcg so far:  0.2954590275744316\n",
      "250,ndcg,0.296063457585+/-0.002,batch_loss, 4.312\n",
      "251,ndcg,0.295630523698+/-0.002,batch_loss, 4.312\n",
      "writing out model with ndcg:  0.2962695150326749  better than best ndcg so far:  0.2960634575846971\n",
      "252,ndcg,0.296269515033+/-0.002,batch_loss, 4.311\n",
      "253,ndcg,0.296204689791+/-0.002,batch_loss, 4.310\n",
      "writing out model with ndcg:  0.2974841688757785  better than best ndcg so far:  0.2962695150326749\n",
      "254,ndcg,0.297484168876+/-0.002,batch_loss, 4.310\n",
      "writing out model with ndcg:  0.29771119282991837  better than best ndcg so far:  0.2974841688757785\n",
      "255,ndcg,0.29771119283+/-0.002,batch_loss, 4.310\n",
      "256,ndcg,0.297570102012+/-0.002,batch_loss, 4.309\n",
      "writing out model with ndcg:  0.2979561190621021  better than best ndcg so far:  0.29771119282991837\n",
      "257,ndcg,0.297956119062+/-0.002,batch_loss, 4.308\n",
      "writing out model with ndcg:  0.29824942488857115  better than best ndcg so far:  0.2979561190621021\n",
      "258,ndcg,0.298249424889+/-0.002,batch_loss, 4.308\n",
      "writing out model with ndcg:  0.2990078036312108  better than best ndcg so far:  0.29824942488857115\n",
      "259,ndcg,0.299007803631+/-0.002,batch_loss, 4.308\n",
      "260,ndcg,0.298627478287+/-0.002,batch_loss, 4.307\n",
      "writing out model with ndcg:  0.2993363418336674  better than best ndcg so far:  0.2990078036312108\n",
      "261,ndcg,0.299336341834+/-0.002,batch_loss, 4.306\n",
      "writing out model with ndcg:  0.2997052081375796  better than best ndcg so far:  0.2993363418336674\n",
      "262,ndcg,0.299705208138+/-0.002,batch_loss, 4.306\n",
      "writing out model with ndcg:  0.30062002737231297  better than best ndcg so far:  0.2997052081375796\n",
      "263,ndcg,0.300620027372+/-0.002,batch_loss, 4.306\n",
      "writing out model with ndcg:  0.3009869245093497  better than best ndcg so far:  0.30062002737231297\n",
      "264,ndcg,0.300986924509+/-0.002,batch_loss, 4.305\n",
      "writing out model with ndcg:  0.3010372045293216  better than best ndcg so far:  0.3009869245093497\n",
      "265,ndcg,0.301037204529+/-0.002,batch_loss, 4.305\n",
      "writing out model with ndcg:  0.3012285436270247  better than best ndcg so far:  0.3010372045293216\n",
      "266,ndcg,0.301228543627+/-0.002,batch_loss, 4.304\n",
      "267,ndcg,0.30118293503+/-0.002,batch_loss, 4.304\n",
      "writing out model with ndcg:  0.3017971580905501  better than best ndcg so far:  0.3012285436270247\n",
      "268,ndcg,0.301797158091+/-0.002,batch_loss, 4.303\n",
      "269,ndcg,0.301771816143+/-0.002,batch_loss, 4.303\n",
      "writing out model with ndcg:  0.3024925751385275  better than best ndcg so far:  0.3017971580905501\n",
      "270,ndcg,0.302492575139+/-0.002,batch_loss, 4.303\n",
      "writing out model with ndcg:  0.3031736668344795  better than best ndcg so far:  0.3024925751385275\n",
      "271,ndcg,0.303173666834+/-0.002,batch_loss, 4.303\n",
      "272,ndcg,0.302935756541+/-0.002,batch_loss, 4.302\n",
      "writing out model with ndcg:  0.3035857888014321  better than best ndcg so far:  0.3031736668344795\n",
      "273,ndcg,0.303585788801+/-0.002,batch_loss, 4.301\n",
      "writing out model with ndcg:  0.30394965626397064  better than best ndcg so far:  0.3035857888014321\n",
      "274,ndcg,0.303949656264+/-0.002,batch_loss, 4.301\n",
      "writing out model with ndcg:  0.3041238411594496  better than best ndcg so far:  0.30394965626397064\n",
      "275,ndcg,0.304123841159+/-0.002,batch_loss, 4.301\n",
      "writing out model with ndcg:  0.3047160751414991  better than best ndcg so far:  0.3041238411594496\n",
      "276,ndcg,0.304716075141+/-0.002,batch_loss, 4.301\n",
      "writing out model with ndcg:  0.3050078957776659  better than best ndcg so far:  0.3047160751414991\n",
      "277,ndcg,0.305007895778+/-0.002,batch_loss, 4.300\n",
      "278,ndcg,0.304793380592+/-0.002,batch_loss, 4.300\n",
      "279,ndcg,0.304863155314+/-0.002,batch_loss, 4.299\n",
      "writing out model with ndcg:  0.30610116405598026  better than best ndcg so far:  0.3050078957776659\n",
      "280,ndcg,0.306101164056+/-0.002,batch_loss, 4.299\n",
      "281,ndcg,0.305675835835+/-0.002,batch_loss, 4.298\n",
      "writing out model with ndcg:  0.3067892449957443  better than best ndcg so far:  0.30610116405598026\n",
      "282,ndcg,0.306789244996+/-0.002,batch_loss, 4.298\n",
      "283,ndcg,0.30662284238+/-0.002,batch_loss, 4.298\n",
      "284,ndcg,0.306739690483+/-0.002,batch_loss, 4.297\n",
      "writing out model with ndcg:  0.3071263369869261  better than best ndcg so far:  0.3067892449957443\n",
      "285,ndcg,0.307126336987+/-0.002,batch_loss, 4.297\n",
      "writing out model with ndcg:  0.30724762857203214  better than best ndcg so far:  0.3071263369869261\n",
      "286,ndcg,0.307247628572+/-0.002,batch_loss, 4.297\n",
      "writing out model with ndcg:  0.3077705776279182  better than best ndcg so far:  0.30724762857203214\n",
      "287,ndcg,0.307770577628+/-0.002,batch_loss, 4.296\n",
      "writing out model with ndcg:  0.3081155434124317  better than best ndcg so far:  0.3077705776279182\n",
      "288,ndcg,0.308115543412+/-0.002,batch_loss, 4.296\n",
      "writing out model with ndcg:  0.30836670300395597  better than best ndcg so far:  0.3081155434124317\n",
      "289,ndcg,0.308366703004+/-0.002,batch_loss, 4.295\n",
      "290,ndcg,0.308317137931+/-0.002,batch_loss, 4.295\n",
      "291,ndcg,0.308330543133+/-0.002,batch_loss, 4.295\n",
      "writing out model with ndcg:  0.30893170353893723  better than best ndcg so far:  0.30836670300395597\n",
      "292,ndcg,0.308931703539+/-0.002,batch_loss, 4.294\n",
      "writing out model with ndcg:  0.3095135885499419  better than best ndcg so far:  0.30893170353893723\n",
      "293,ndcg,0.30951358855+/-0.002,batch_loss, 4.294\n",
      "writing out model with ndcg:  0.3096286322917271  better than best ndcg so far:  0.3095135885499419\n",
      "294,ndcg,0.309628632292+/-0.002,batch_loss, 4.293\n",
      "writing out model with ndcg:  0.3104620782473105  better than best ndcg so far:  0.3096286322917271\n",
      "295,ndcg,0.310462078247+/-0.002,batch_loss, 4.293\n",
      "296,ndcg,0.310117667366+/-0.002,batch_loss, 4.293\n",
      "297,ndcg,0.310420151091+/-0.002,batch_loss, 4.293\n",
      "298,ndcg,0.310118741396+/-0.002,batch_loss, 4.293\n",
      "writing out model with ndcg:  0.31083629008992336  better than best ndcg so far:  0.3104620782473105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299,ndcg,0.31083629009+/-0.002,batch_loss, 4.293\n",
      "writing out model with ndcg:  0.311157652655782  better than best ndcg so far:  0.31083629008992336\n",
      "300,ndcg,0.311157652656+/-0.002,batch_loss, 4.292\n",
      "writing out model with ndcg:  0.31123673327233037  better than best ndcg so far:  0.311157652655782\n",
      "301,ndcg,0.311236733272+/-0.002,batch_loss, 4.292\n",
      "writing out model with ndcg:  0.31128030423824965  better than best ndcg so far:  0.31123673327233037\n",
      "302,ndcg,0.311280304238+/-0.002,batch_loss, 4.291\n",
      "writing out model with ndcg:  0.31160360193912173  better than best ndcg so far:  0.31128030423824965\n",
      "303,ndcg,0.311603601939+/-0.002,batch_loss, 4.291\n",
      "writing out model with ndcg:  0.31222648107824086  better than best ndcg so far:  0.31160360193912173\n",
      "304,ndcg,0.312226481078+/-0.002,batch_loss, 4.291\n",
      "305,ndcg,0.311585057726+/-0.002,batch_loss, 4.291\n",
      "writing out model with ndcg:  0.31280387954481736  better than best ndcg so far:  0.31222648107824086\n",
      "306,ndcg,0.312803879545+/-0.002,batch_loss, 4.290\n",
      "307,ndcg,0.312611949136+/-0.002,batch_loss, 4.290\n",
      "308,ndcg,0.31239576616+/-0.002,batch_loss, 4.289\n",
      "309,ndcg,0.312644454522+/-0.002,batch_loss, 4.289\n",
      "writing out model with ndcg:  0.3128517615003192  better than best ndcg so far:  0.31280387954481736\n",
      "310,ndcg,0.3128517615+/-0.002,batch_loss, 4.289\n",
      "writing out model with ndcg:  0.3132888595884919  better than best ndcg so far:  0.3128517615003192\n",
      "311,ndcg,0.313288859588+/-0.002,batch_loss, 4.288\n",
      "writing out model with ndcg:  0.3138238620922688  better than best ndcg so far:  0.3132888595884919\n",
      "312,ndcg,0.313823862092+/-0.002,batch_loss, 4.288\n",
      "313,ndcg,0.313154770763+/-0.002,batch_loss, 4.288\n",
      "314,ndcg,0.313281714778+/-0.002,batch_loss, 4.287\n",
      "writing out model with ndcg:  0.3140356358907862  better than best ndcg so far:  0.3138238620922688\n",
      "315,ndcg,0.314035635891+/-0.002,batch_loss, 4.287\n",
      "writing out model with ndcg:  0.3142761902118826  better than best ndcg so far:  0.3140356358907862\n",
      "316,ndcg,0.314276190212+/-0.002,batch_loss, 4.287\n",
      "writing out model with ndcg:  0.3144938380643921  better than best ndcg so far:  0.3142761902118826\n",
      "317,ndcg,0.314493838064+/-0.002,batch_loss, 4.287\n",
      "318,ndcg,0.314389752386+/-0.002,batch_loss, 4.286\n",
      "writing out model with ndcg:  0.31480160432894244  better than best ndcg so far:  0.3144938380643921\n",
      "319,ndcg,0.314801604329+/-0.002,batch_loss, 4.286\n",
      "writing out model with ndcg:  0.3148775092983255  better than best ndcg so far:  0.31480160432894244\n",
      "320,ndcg,0.314877509298+/-0.002,batch_loss, 4.286\n",
      "321,ndcg,0.314726831522+/-0.002,batch_loss, 4.285\n",
      "322,ndcg,0.314364412104+/-0.002,batch_loss, 4.285\n",
      "writing out model with ndcg:  0.3158796957493859  better than best ndcg so far:  0.3148775092983255\n",
      "323,ndcg,0.315879695749+/-0.002,batch_loss, 4.285\n",
      "324,ndcg,0.31572081089+/-0.002,batch_loss, 4.285\n",
      "325,ndcg,0.315584673386+/-0.002,batch_loss, 4.285\n",
      "326,ndcg,0.31525107989+/-0.002,batch_loss, 4.284\n",
      "writing out model with ndcg:  0.3160681054771011  better than best ndcg so far:  0.3158796957493859\n",
      "327,ndcg,0.316068105477+/-0.002,batch_loss, 4.284\n",
      "328,ndcg,0.315700219067+/-0.002,batch_loss, 4.284\n",
      "writing out model with ndcg:  0.316177998816489  better than best ndcg so far:  0.3160681054771011\n",
      "329,ndcg,0.316177998816+/-0.002,batch_loss, 4.284\n",
      "writing out model with ndcg:  0.3161985170797179  better than best ndcg so far:  0.316177998816489\n",
      "330,ndcg,0.31619851708+/-0.002,batch_loss, 4.284\n",
      "writing out model with ndcg:  0.31650290853895074  better than best ndcg so far:  0.3161985170797179\n",
      "331,ndcg,0.316502908539+/-0.002,batch_loss, 4.283\n",
      "writing out model with ndcg:  0.317253969245759  better than best ndcg so far:  0.31650290853895074\n",
      "332,ndcg,0.317253969246+/-0.002,batch_loss, 4.283\n",
      "333,ndcg,0.316584780592+/-0.002,batch_loss, 4.282\n",
      "334,ndcg,0.316495623751+/-0.002,batch_loss, 4.282\n",
      "335,ndcg,0.31679808967+/-0.002,batch_loss, 4.282\n",
      "writing out model with ndcg:  0.317345832072  better than best ndcg so far:  0.317253969245759\n",
      "336,ndcg,0.317345832072+/-0.002,batch_loss, 4.282\n",
      "writing out model with ndcg:  0.31810147982779463  better than best ndcg so far:  0.317345832072\n",
      "337,ndcg,0.318101479828+/-0.002,batch_loss, 4.282\n",
      "338,ndcg,0.317299560534+/-0.002,batch_loss, 4.281\n",
      "339,ndcg,0.31773305313+/-0.002,batch_loss, 4.281\n",
      "340,ndcg,0.317193393187+/-0.002,batch_loss, 4.281\n",
      "341,ndcg,0.317816014979+/-0.002,batch_loss, 4.281\n",
      "342,ndcg,0.317347963993+/-0.002,batch_loss, 4.280\n",
      "343,ndcg,0.317761003318+/-0.002,batch_loss, 4.280\n",
      "344,ndcg,0.317782986677+/-0.002,batch_loss, 4.280\n",
      "writing out model with ndcg:  0.3183341467989905  better than best ndcg so far:  0.31810147982779463\n",
      "345,ndcg,0.318334146799+/-0.002,batch_loss, 4.280\n",
      "346,ndcg,0.317619164121+/-0.002,batch_loss, 4.279\n",
      "writing out model with ndcg:  0.3186132662737274  better than best ndcg so far:  0.3183341467989905\n",
      "347,ndcg,0.318613266274+/-0.002,batch_loss, 4.279\n",
      "348,ndcg,0.318574749877+/-0.002,batch_loss, 4.279\n",
      "writing out model with ndcg:  0.31863810484921806  better than best ndcg so far:  0.3186132662737274\n",
      "349,ndcg,0.318638104849+/-0.002,batch_loss, 4.279\n",
      "350,ndcg,0.317986112818+/-0.002,batch_loss, 4.278\n",
      "351,ndcg,0.318432870777+/-0.002,batch_loss, 4.278\n",
      "writing out model with ndcg:  0.3191140026112966  better than best ndcg so far:  0.31863810484921806\n",
      "352,ndcg,0.319114002611+/-0.002,batch_loss, 4.278\n",
      "353,ndcg,0.318654838817+/-0.002,batch_loss, 4.278\n",
      "354,ndcg,0.318828349515+/-0.002,batch_loss, 4.277\n",
      "writing out model with ndcg:  0.31939014804147375  better than best ndcg so far:  0.3191140026112966\n",
      "355,ndcg,0.319390148041+/-0.002,batch_loss, 4.277\n",
      "356,ndcg,0.319302022195+/-0.002,batch_loss, 4.277\n",
      "357,ndcg,0.319377356243+/-0.002,batch_loss, 4.277\n",
      "writing out model with ndcg:  0.3193901547281491  better than best ndcg so far:  0.31939014804147375\n",
      "358,ndcg,0.319390154728+/-0.002,batch_loss, 4.277\n",
      "writing out model with ndcg:  0.3198748582798529  better than best ndcg so far:  0.3193901547281491\n",
      "359,ndcg,0.31987485828+/-0.002,batch_loss, 4.277\n",
      "360,ndcg,0.319416187304+/-0.002,batch_loss, 4.277\n",
      "361,ndcg,0.319119558874+/-0.002,batch_loss, 4.276\n",
      "writing out model with ndcg:  0.3199505528219332  better than best ndcg so far:  0.3198748582798529\n",
      "362,ndcg,0.319950552822+/-0.002,batch_loss, 4.276\n",
      "363,ndcg,0.319256722887+/-0.002,batch_loss, 4.275\n",
      "364,ndcg,0.319622878158+/-0.002,batch_loss, 4.275\n",
      "writing out model with ndcg:  0.3202385156823411  better than best ndcg so far:  0.3199505528219332\n",
      "365,ndcg,0.320238515682+/-0.002,batch_loss, 4.275\n",
      "366,ndcg,0.319746438982+/-0.002,batch_loss, 4.275\n",
      "367,ndcg,0.320195566152+/-0.002,batch_loss, 4.275\n",
      "368,ndcg,0.319824037734+/-0.002,batch_loss, 4.275\n",
      "369,ndcg,0.320117003574+/-0.002,batch_loss, 4.274\n",
      "writing out model with ndcg:  0.32043616912911843  better than best ndcg so far:  0.3202385156823411\n",
      "370,ndcg,0.320436169129+/-0.002,batch_loss, 4.274\n",
      "writing out model with ndcg:  0.3204978908939106  better than best ndcg so far:  0.32043616912911843\n",
      "371,ndcg,0.320497890894+/-0.002,batch_loss, 4.274\n",
      "372,ndcg,0.320130180454+/-0.002,batch_loss, 4.274\n",
      "writing out model with ndcg:  0.3206605861295313  better than best ndcg so far:  0.3204978908939106\n",
      "373,ndcg,0.32066058613+/-0.002,batch_loss, 4.273\n",
      "374,ndcg,0.319977493641+/-0.002,batch_loss, 4.274\n",
      "375,ndcg,0.320330815147+/-0.002,batch_loss, 4.273\n",
      "376,ndcg,0.320616411107+/-0.002,batch_loss, 4.273\n",
      "377,ndcg,0.320542900581+/-0.002,batch_loss, 4.273\n",
      "writing out model with ndcg:  0.32070754364881404  better than best ndcg so far:  0.3206605861295313\n",
      "378,ndcg,0.320707543649+/-0.002,batch_loss, 4.273\n",
      "writing out model with ndcg:  0.32084963921953286  better than best ndcg so far:  0.32070754364881404\n",
      "379,ndcg,0.32084963922+/-0.002,batch_loss, 4.272\n",
      "writing out model with ndcg:  0.3210731333900046  better than best ndcg so far:  0.32084963921953286\n",
      "380,ndcg,0.32107313339+/-0.002,batch_loss, 4.272\n",
      "381,ndcg,0.320975420959+/-0.002,batch_loss, 4.272\n",
      "382,ndcg,0.320436095275+/-0.002,batch_loss, 4.272\n",
      "383,ndcg,0.320893470173+/-0.002,batch_loss, 4.272\n",
      "writing out model with ndcg:  0.3215648642883124  better than best ndcg so far:  0.3210731333900046\n",
      "384,ndcg,0.321564864288+/-0.002,batch_loss, 4.272\n",
      "385,ndcg,0.320991315603+/-0.002,batch_loss, 4.271\n",
      "386,ndcg,0.321126896242+/-0.002,batch_loss, 4.270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387,ndcg,0.321198338344+/-0.002,batch_loss, 4.271\n",
      "388,ndcg,0.321027928541+/-0.002,batch_loss, 4.270\n",
      "389,ndcg,0.321126315021+/-0.002,batch_loss, 4.271\n",
      "390,ndcg,0.321524337071+/-0.002,batch_loss, 4.270\n",
      "writing out model with ndcg:  0.32161363876325566  better than best ndcg so far:  0.3215648642883124\n",
      "391,ndcg,0.321613638763+/-0.002,batch_loss, 4.270\n",
      "392,ndcg,0.321112071144+/-0.002,batch_loss, 4.270\n",
      "393,ndcg,0.321326217838+/-0.002,batch_loss, 4.270\n",
      "394,ndcg,0.32151215077+/-0.002,batch_loss, 4.270\n",
      "writing out model with ndcg:  0.3222008850017651  better than best ndcg so far:  0.32161363876325566\n",
      "395,ndcg,0.322200885002+/-0.002,batch_loss, 4.269\n",
      "396,ndcg,0.321847757022+/-0.002,batch_loss, 4.269\n",
      "397,ndcg,0.320720412341+/-0.002,batch_loss, 4.269\n",
      "398,ndcg,0.321624935893+/-0.002,batch_loss, 4.269\n",
      "writing out model with ndcg:  0.3224280499736297  better than best ndcg so far:  0.3222008850017651\n",
      "399,ndcg,0.322428049974+/-0.002,batch_loss, 4.268\n",
      "400,ndcg,0.321495198215+/-0.002,batch_loss, 4.268\n",
      "401,ndcg,0.322111622531+/-0.002,batch_loss, 4.268\n",
      "402,ndcg,0.321300782294+/-0.002,batch_loss, 4.268\n",
      "writing out model with ndcg:  0.3224360425694349  better than best ndcg so far:  0.3224280499736297\n",
      "403,ndcg,0.322436042569+/-0.002,batch_loss, 4.268\n",
      "404,ndcg,0.321520463372+/-0.002,batch_loss, 4.268\n",
      "405,ndcg,0.32159769975+/-0.002,batch_loss, 4.267\n",
      "406,ndcg,0.321846929966+/-0.002,batch_loss, 4.267\n",
      "407,ndcg,0.321816900538+/-0.002,batch_loss, 4.267\n",
      "408,ndcg,0.321791107101+/-0.002,batch_loss, 4.267\n",
      "409,ndcg,0.321806441071+/-0.002,batch_loss, 4.267\n",
      "410,ndcg,0.322219476646+/-0.002,batch_loss, 4.266\n",
      "411,ndcg,0.321683606773+/-0.002,batch_loss, 4.267\n",
      "412,ndcg,0.321299646045+/-0.002,batch_loss, 4.266\n",
      "413,ndcg,0.321730763701+/-0.002,batch_loss, 4.266\n",
      "414,ndcg,0.322001323488+/-0.002,batch_loss, 4.266\n",
      "415,ndcg,0.322251865783+/-0.002,batch_loss, 4.266\n",
      "416,ndcg,0.321180518649+/-0.002,batch_loss, 4.265\n",
      "417,ndcg,0.321757645168+/-0.002,batch_loss, 4.265\n",
      "418,ndcg,0.322097882268+/-0.002,batch_loss, 4.265\n",
      "419,ndcg,0.322328646855+/-0.002,batch_loss, 4.266\n",
      "420,ndcg,0.321940995886+/-0.002,batch_loss, 4.265\n",
      "421,ndcg,0.321487444574+/-0.002,batch_loss, 4.265\n",
      "422,ndcg,0.321590360519+/-0.002,batch_loss, 4.265\n",
      "423,ndcg,0.322022326265+/-0.002,batch_loss, 4.264\n",
      "424,ndcg,0.321757691072+/-0.002,batch_loss, 4.264\n",
      "425,ndcg,0.322094977741+/-0.002,batch_loss, 4.264\n",
      "426,ndcg,0.322176770672+/-0.002,batch_loss, 4.264\n",
      "427,ndcg,0.322258887038+/-0.002,batch_loss, 4.264\n",
      "428,ndcg,0.321759991956+/-0.002,batch_loss, 4.264\n",
      "429,ndcg,0.322012258694+/-0.002,batch_loss, 4.264\n",
      "430,ndcg,0.322292720891+/-0.002,batch_loss, 4.264\n",
      "431,ndcg,0.321611346078+/-0.002,batch_loss, 4.263\n",
      "writing out model with ndcg:  0.3224434252953966  better than best ndcg so far:  0.3224360425694349\n",
      "432,ndcg,0.322443425295+/-0.002,batch_loss, 4.263\n",
      "433,ndcg,0.322251881295+/-0.002,batch_loss, 4.263\n",
      "434,ndcg,0.321958784292+/-0.002,batch_loss, 4.263\n",
      "435,ndcg,0.322092113732+/-0.002,batch_loss, 4.262\n",
      "436,ndcg,0.321878583739+/-0.002,batch_loss, 4.263\n",
      "437,ndcg,0.321753713081+/-0.002,batch_loss, 4.263\n",
      "438,ndcg,0.32180391899+/-0.002,batch_loss, 4.263\n",
      "439,ndcg,0.32243182908+/-0.002,batch_loss, 4.262\n",
      "writing out model with ndcg:  0.32271787298942234  better than best ndcg so far:  0.3224434252953966\n",
      "440,ndcg,0.322717872989+/-0.002,batch_loss, 4.262\n",
      "441,ndcg,0.322238114014+/-0.002,batch_loss, 4.262\n",
      "442,ndcg,0.321944282452+/-0.002,batch_loss, 4.261\n",
      "443,ndcg,0.321748506197+/-0.002,batch_loss, 4.262\n",
      "444,ndcg,0.322063397672+/-0.002,batch_loss, 4.262\n",
      "445,ndcg,0.322494129465+/-0.002,batch_loss, 4.261\n",
      "446,ndcg,0.322593716606+/-0.002,batch_loss, 4.260\n",
      "447,ndcg,0.322469627333+/-0.002,batch_loss, 4.260\n",
      "448,ndcg,0.321886085299+/-0.002,batch_loss, 4.260\n",
      "449,ndcg,0.322399642415+/-0.002,batch_loss, 4.261\n",
      "450,ndcg,0.322262848377+/-0.002,batch_loss, 4.261\n",
      "451,ndcg,0.322606176223+/-0.002,batch_loss, 4.261\n",
      "452,ndcg,0.322073708995+/-0.002,batch_loss, 4.261\n",
      "writing out model with ndcg:  0.32285401161454036  better than best ndcg so far:  0.32271787298942234\n",
      "453,ndcg,0.322854011615+/-0.002,batch_loss, 4.260\n",
      "454,ndcg,0.322512525277+/-0.002,batch_loss, 4.260\n",
      "455,ndcg,0.321990144028+/-0.002,batch_loss, 4.260\n",
      "456,ndcg,0.322026752946+/-0.002,batch_loss, 4.259\n",
      "457,ndcg,0.32250730047+/-0.002,batch_loss, 4.259\n",
      "458,ndcg,0.321850462379+/-0.002,batch_loss, 4.259\n",
      "459,ndcg,0.321586997008+/-0.002,batch_loss, 4.259\n",
      "460,ndcg,0.322555858447+/-0.002,batch_loss, 4.260\n",
      "461,ndcg,0.321994755318+/-0.002,batch_loss, 4.259\n",
      "462,ndcg,0.321999858882+/-0.002,batch_loss, 4.259\n",
      "463,ndcg,0.321911660028+/-0.002,batch_loss, 4.259\n",
      "464,ndcg,0.322411017832+/-0.002,batch_loss, 4.259\n",
      "465,ndcg,0.322106500554+/-0.002,batch_loss, 4.258\n",
      "466,ndcg,0.322626515868+/-0.002,batch_loss, 4.258\n",
      "467,ndcg,0.322246941354+/-0.002,batch_loss, 4.258\n",
      "468,ndcg,0.322126947866+/-0.002,batch_loss, 4.258\n",
      "469,ndcg,0.322202015212+/-0.002,batch_loss, 4.258\n",
      "470,ndcg,0.322026929704+/-0.002,batch_loss, 4.257\n",
      "471,ndcg,0.322075580224+/-0.002,batch_loss, 4.257\n",
      "472,ndcg,0.322078432775+/-0.002,batch_loss, 4.258\n",
      "473,ndcg,0.322501229167+/-0.002,batch_loss, 4.258\n",
      "474,ndcg,0.322083235591+/-0.002,batch_loss, 4.258\n",
      "475,ndcg,0.322446505662+/-0.002,batch_loss, 4.257\n",
      "476,ndcg,0.322765393621+/-0.002,batch_loss, 4.257\n",
      "477,ndcg,0.321896078041+/-0.002,batch_loss, 4.257\n",
      "478,ndcg,0.321494770321+/-0.002,batch_loss, 4.256\n",
      "writing out model with ndcg:  0.3229092937205999  better than best ndcg so far:  0.32285401161454036\n",
      "479,ndcg,0.322909293721+/-0.002,batch_loss, 4.257\n",
      "480,ndcg,0.322266763439+/-0.002,batch_loss, 4.257\n",
      "481,ndcg,0.322278670426+/-0.002,batch_loss, 4.257\n",
      "482,ndcg,0.322057885662+/-0.002,batch_loss, 4.257\n",
      "483,ndcg,0.322437193089+/-0.002,batch_loss, 4.256\n",
      "484,ndcg,0.321999548232+/-0.002,batch_loss, 4.256\n",
      "485,ndcg,0.321807713825+/-0.002,batch_loss, 4.256\n",
      "486,ndcg,0.322642634318+/-0.002,batch_loss, 4.256\n",
      "487,ndcg,0.322533963365+/-0.002,batch_loss, 4.255\n",
      "488,ndcg,0.322329650286+/-0.002,batch_loss, 4.255\n",
      "489,ndcg,0.322348040702+/-0.002,batch_loss, 4.255\n",
      "490,ndcg,0.322474124785+/-0.002,batch_loss, 4.255\n",
      "491,ndcg,0.322315983177+/-0.002,batch_loss, 4.255\n",
      "492,ndcg,0.321997640243+/-0.002,batch_loss, 4.255\n",
      "493,ndcg,0.322201613968+/-0.002,batch_loss, 4.255\n",
      "494,ndcg,0.322810553492+/-0.002,batch_loss, 4.255\n",
      "495,ndcg,0.32239214747+/-0.002,batch_loss, 4.255\n",
      "496,ndcg,0.322131539171+/-0.002,batch_loss, 4.255\n",
      "497,ndcg,0.322581237847+/-0.002,batch_loss, 4.254\n",
      "498,ndcg,0.322129847611+/-0.002,batch_loss, 4.255\n",
      "499,ndcg,0.322888131498+/-0.002,batch_loss, 4.254\n",
      "500,ndcg,0.322527413217+/-0.002,batch_loss, 4.254\n",
      "501,ndcg,0.322454513962+/-0.002,batch_loss, 4.254\n",
      "502,ndcg,0.322034610549+/-0.002,batch_loss, 4.254\n",
      "503,ndcg,0.322063016616+/-0.002,batch_loss, 4.254\n",
      "504,ndcg,0.322389490809+/-0.002,batch_loss, 4.254\n",
      "505,ndcg,0.32231678174+/-0.002,batch_loss, 4.254\n",
      "506,ndcg,0.322031075296+/-0.002,batch_loss, 4.254\n",
      "507,ndcg,0.322542822353+/-0.002,batch_loss, 4.253\n",
      "508,ndcg,0.32226910485+/-0.002,batch_loss, 4.253\n",
      "509,ndcg,0.322291239089+/-0.002,batch_loss, 4.253\n",
      "510,ndcg,0.322350003001+/-0.002,batch_loss, 4.253\n",
      "511,ndcg,0.321929898867+/-0.002,batch_loss, 4.253\n",
      "512,ndcg,0.322299624338+/-0.002,batch_loss, 4.253\n",
      "513,ndcg,0.322130649917+/-0.002,batch_loss, 4.253\n",
      "514,ndcg,0.321752729981+/-0.002,batch_loss, 4.252\n",
      "515,ndcg,0.322661883897+/-0.002,batch_loss, 4.252\n",
      "516,ndcg,0.321707471684+/-0.002,batch_loss, 4.252\n",
      "517,ndcg,0.322358469048+/-0.002,batch_loss, 4.252\n",
      "518,ndcg,0.322210199071+/-0.002,batch_loss, 4.252\n",
      "519,ndcg,0.322235379642+/-0.002,batch_loss, 4.252\n",
      "520,ndcg,0.322216488239+/-0.002,batch_loss, 4.252\n",
      "521,ndcg,0.322033962434+/-0.002,batch_loss, 4.252\n",
      "522,ndcg,0.322210976246+/-0.002,batch_loss, 4.252\n",
      "523,ndcg,0.321827981098+/-0.002,batch_loss, 4.251\n",
      "524,ndcg,0.322700926756+/-0.002,batch_loss, 4.252\n",
      "525,ndcg,0.321887419529+/-0.002,batch_loss, 4.251\n",
      "526,ndcg,0.32207652446+/-0.002,batch_loss, 4.251\n",
      "527,ndcg,0.321983099416+/-0.002,batch_loss, 4.251\n",
      "528,ndcg,0.322056172409+/-0.002,batch_loss, 4.250\n",
      "529,ndcg,0.322467936658+/-0.002,batch_loss, 4.250\n",
      "530,ndcg,0.322205578199+/-0.002,batch_loss, 4.251\n",
      "531,ndcg,0.322586118434+/-0.002,batch_loss, 4.251\n",
      "532,ndcg,0.322418444404+/-0.002,batch_loss, 4.250\n",
      "533,ndcg,0.322109930576+/-0.002,batch_loss, 4.250\n",
      "534,ndcg,0.322565865219+/-0.002,batch_loss, 4.251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535,ndcg,0.321819316741+/-0.002,batch_loss, 4.251\n",
      "536,ndcg,0.32183806307+/-0.002,batch_loss, 4.251\n",
      "537,ndcg,0.322510008049+/-0.002,batch_loss, 4.250\n",
      "538,ndcg,0.322540762355+/-0.002,batch_loss, 4.250\n",
      "539,ndcg,0.322223347298+/-0.002,batch_loss, 4.250\n",
      "540,ndcg,0.321835795942+/-0.002,batch_loss, 4.250\n",
      "541,ndcg,0.32174893345+/-0.002,batch_loss, 4.249\n",
      "542,ndcg,0.322212029332+/-0.002,batch_loss, 4.250\n",
      "543,ndcg,0.322006057461+/-0.002,batch_loss, 4.250\n",
      "544,ndcg,0.322324201808+/-0.002,batch_loss, 4.249\n",
      "545,ndcg,0.322234036905+/-0.002,batch_loss, 4.249\n",
      "546,ndcg,0.321493541354+/-0.002,batch_loss, 4.249\n",
      "547,ndcg,0.322455733711+/-0.002,batch_loss, 4.249\n",
      "548,ndcg,0.322130046728+/-0.002,batch_loss, 4.249\n",
      "549,ndcg,0.321880083194+/-0.002,batch_loss, 4.249\n",
      "550,ndcg,0.322445236611+/-0.002,batch_loss, 4.249\n",
      "551,ndcg,0.321427905402+/-0.002,batch_loss, 4.249\n",
      "552,ndcg,0.322177569403+/-0.002,batch_loss, 4.249\n",
      "553,ndcg,0.321786296672+/-0.002,batch_loss, 4.249\n",
      "554,ndcg,0.321925289242+/-0.002,batch_loss, 4.248\n",
      "555,ndcg,0.322410926636+/-0.002,batch_loss, 4.248\n",
      "556,ndcg,0.322023177725+/-0.002,batch_loss, 4.248\n",
      "557,ndcg,0.321424416114+/-0.002,batch_loss, 4.248\n",
      "558,ndcg,0.32226400964+/-0.002,batch_loss, 4.248\n",
      "559,ndcg,0.321955313178+/-0.002,batch_loss, 4.248\n",
      "560,ndcg,0.321577158774+/-0.002,batch_loss, 4.247\n",
      "561,ndcg,0.322044082981+/-0.002,batch_loss, 4.247\n",
      "562,ndcg,0.322609637521+/-0.002,batch_loss, 4.247\n",
      "563,ndcg,0.322000816954+/-0.002,batch_loss, 4.247\n",
      "564,ndcg,0.321437401013+/-0.002,batch_loss, 4.247\n",
      "565,ndcg,0.321981567067+/-0.002,batch_loss, 4.247\n",
      "566,ndcg,0.322255938093+/-0.002,batch_loss, 4.247\n",
      "567,ndcg,0.322272434822+/-0.002,batch_loss, 4.247\n",
      "568,ndcg,0.322297978145+/-0.002,batch_loss, 4.247\n",
      "569,ndcg,0.321611658606+/-0.002,batch_loss, 4.247\n",
      "570,ndcg,0.321655273203+/-0.002,batch_loss, 4.247\n",
      "571,ndcg,0.321488701778+/-0.002,batch_loss, 4.247\n",
      "572,ndcg,0.322086133059+/-0.002,batch_loss, 4.247\n",
      "573,ndcg,0.322104703202+/-0.002,batch_loss, 4.247\n",
      "574,ndcg,0.322094614912+/-0.002,batch_loss, 4.247\n",
      "575,ndcg,0.321936874894+/-0.002,batch_loss, 4.247\n",
      "576,ndcg,0.322298734741+/-0.002,batch_loss, 4.246\n",
      "577,ndcg,0.322210002177+/-0.002,batch_loss, 4.246\n",
      "578,ndcg,0.321903502968+/-0.002,batch_loss, 4.246\n",
      "579,ndcg,0.321835854538+/-0.002,batch_loss, 4.245\n",
      "580,ndcg,0.321970867897+/-0.002,batch_loss, 4.246\n",
      "581,ndcg,0.321805929877+/-0.002,batch_loss, 4.246\n",
      "582,ndcg,0.322191198477+/-0.002,batch_loss, 4.246\n",
      "583,ndcg,0.321845286253+/-0.002,batch_loss, 4.246\n",
      "584,ndcg,0.321617061168+/-0.002,batch_loss, 4.245\n",
      "585,ndcg,0.322320345183+/-0.002,batch_loss, 4.246\n",
      "586,ndcg,0.32169530762+/-0.002,batch_loss, 4.245\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    model1 = Model1(num_users,\n",
    "                    num_items,\n",
    "                    num_tags,\n",
    "                    num_factors,\n",
    "                    var_prior,\n",
    "                    video_metadata_array,\n",
    "                    availability,\n",
    "                    model_variational,\n",
    "                    model_censored,\n",
    "                    model_user_tags,\n",
    "                    model_video_tags)\n",
    "    batch_logits, batch_logits_validation, log_softmax, avg_loss, batch_conditional_log_likelihood,\\\n",
    "    num_items_per_document = model1.construct_graph()\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=lr)\\\n",
    "    .minimize(avg_loss, global_step=tf.Variable(0, name='global_step_1', trainable=False))\n",
    "\n",
    "    ####Tensors for validation####\n",
    "    train_op_validation = tf.train.AdamOptimizer(learning_rate=lr)\\\n",
    "    .minimize(avg_loss,\n",
    "              var_list = [model1.Mu_Zu, model1.lsdev_Zu],\n",
    "              global_step=tf.Variable(0, name='global_step_1_validation', trainable=False))\n",
    "\n",
    "    ####Summary####\n",
    "    avg_loss_summary_ph = tf.placeholder(dtype = tf.float32)\n",
    "    tf.summary.scalar('avg_loss', avg_loss_summary_ph)\n",
    "\n",
    "    ndcg_summary_ph = tf.placeholder(dtype=tf.float32)\n",
    "    tf.summary.scalar('ndcg_100', ndcg_summary_ph)\n",
    "    summary = tf.summary.merge_all()\n",
    "\n",
    "    ####Start####\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        summary_writer = tf.summary.FileWriter('{EXP_DIR}/tensorflow_output/{experiment_name}'.format(\n",
    "            EXP_DIR = EXP_DIR,\n",
    "            experiment_name = experiment_name), sess.graph)\n",
    "        sess.run(init)\n",
    "        ndcgs_vad = []\n",
    "        best_ndcg_sofar = -1000\n",
    "        for epoch_ind in np.arange(num_epochs):\n",
    "\n",
    "            ###Optimize parameters for Validation users ####    \n",
    "            avg_loss_validation = 0\n",
    "            num_batches = 0\n",
    "            for batch_ind, st_index in enumerate(range(0, heldout_idxlist.shape[0], batch_size)):\n",
    "                batch_start_time = time.time()\n",
    "                end_index = min(st_index + batch_size, heldout_idxlist.shape[0])\n",
    "                user_indices = heldout_idxlist[st_index:end_index]\n",
    "                X = all_tr_mat[user_indices]\n",
    "                X = X.toarray()\n",
    "                X = X.astype('float32')\n",
    "                \n",
    "                feed_dict = {model1.users_ph : user_indices,\n",
    "                             model1.played_videos_ph : X}\n",
    "                if model_user_tags:\n",
    "                    M_u = np.dot(X, video_tags_mat)\n",
    "                    M_u[M_u > 0] = 1\n",
    "                    num_tags_per_user = M_u.sum(axis = 1)\n",
    "                    num_tags_per_user[num_tags_per_user == 0] = 1\n",
    "                    M_u = M_u / (num_tags_per_user[:, np.newaxis])\n",
    "                    feed_dict[model1.played_tags_ph] = M_u\n",
    "                \n",
    "                _, loss_val = sess.run([train_op_validation, avg_loss], feed_dict=feed_dict)\n",
    "                avg_loss_validation += loss_val\n",
    "                num_batches += 1\n",
    "            avg_loss_validation /= num_batches\n",
    "\n",
    "            ####Metrics Computation####\n",
    "            ndcg_dist = []\n",
    "            for batch_ind, st_index in enumerate(range(0, heldout_idxlist.shape[0], batch_size)):\n",
    "                end_index = min(st_index + batch_size, heldout_idxlist.shape[0])\n",
    "                heldout_user_indices = heldout_idxlist[st_index:end_index]\n",
    "                X = all_tr_mat[heldout_user_indices]\n",
    "                X = X.toarray()\n",
    "                X = X.astype('float32')\n",
    "                feed_dict = {model1.users_ph : heldout_user_indices}\n",
    "                if model_user_tags:\n",
    "                    M_u = np.dot(X, video_tags_mat)\n",
    "                    M_u[M_u > 0] = 1\n",
    "                    num_tags_per_user = M_u.sum(axis = 1)\n",
    "                    num_tags_per_user[num_tags_per_user == 0] = 1.0\n",
    "                    M_u = M_u / (num_tags_per_user[:, np.newaxis])\n",
    "                    feed_dict[model1.played_tags_ph] = M_u\n",
    "                \n",
    "                logit_heldout = sess.run(batch_logits_validation, feed_dict=feed_dict)\n",
    "                logit_heldout[X.nonzero()] = -np.inf\n",
    "                ndcg_dist.append(NDCG_binary_at_k_batch(logit_heldout,\n",
    "                                                        heldout_data_te[heldout_user_indices - heldout_start_index]))\n",
    "            ndcg_dist = np.concatenate(ndcg_dist)\n",
    "            ndcg_ = ndcg_dist.mean()\n",
    "            ndcg_serr = ndcg_dist.std() / np.sqrt(ndcg_dist.shape[0])\n",
    "            ndcgs_vad.append((ndcg_, ndcg_serr))\n",
    "            \n",
    "            if ndcg_ >= best_ndcg_sofar:\n",
    "                print('writing out model with ndcg: ', ndcg_, ' better than best ndcg so far: ', best_ndcg_sofar)\n",
    "                saver.save(sess, os.path.join(EXP_DIR, 'tensorflow_models', experiment_name, 'files'))\n",
    "                best_ndcg_sofar = ndcg_\n",
    "\n",
    "            ####Training####\n",
    "            avg_loss_dataset = 0\n",
    "            num_batches = 0\n",
    "            np.random.shuffle(train_idxlist)\n",
    "            for batch_ind, st_index in enumerate(range(0, train_idxlist.shape[0], batch_size)):\n",
    "                batch_start_time = time.time()\n",
    "                end_index = min(st_index + batch_size, train_idxlist.shape[0])\n",
    "                user_indices = train_idxlist[st_index:end_index]\n",
    "                X = all_tr_mat[user_indices]\n",
    "                X = X.toarray()\n",
    "                X = X.astype('float32')\n",
    "                feed_dict = {model1.users_ph : user_indices, model1.played_videos_ph : X}\n",
    "                '''_, loss_val, batch_conditional_log_likelihood_val,\\\n",
    "                batch_kl_div_val, num_items_per_document_val = sess.run([train_op, avg_loss,\n",
    "                                                                         batch_conditional_log_likelihood, \n",
    "                                                                         batch_kl_div, num_items_per_document ], feed_dict=feed_dict)\n",
    "                #print(batch_conditional_log_likelihood_val.shape, batch_kl_div_val.shape, num_items_per_document_val.shape)\n",
    "                #print(1.0 / num_items_per_document_val)'''\n",
    "                if model_user_tags:\n",
    "                    M_u = np.dot(X, video_tags_mat)\n",
    "                    M_u[M_u > 0] = 1\n",
    "                    num_tags_per_user = M_u.sum(axis = 1)\n",
    "                    num_tags_per_user[num_tags_per_user == 0] = 1\n",
    "                    M_u = M_u / (num_tags_per_user[:, np.newaxis])\n",
    "                    feed_dict[model1.played_tags_ph] = M_u\n",
    "                \n",
    "                _, loss_val =\\\n",
    "                sess.run([train_op, avg_loss], feed_dict=feed_dict)\n",
    "                #print(log_softmax_val.shape)\n",
    "                avg_loss_dataset += loss_val\n",
    "                num_batches += 1\n",
    "            avg_loss_dataset = avg_loss_dataset / max(num_batches, 1)\n",
    "            ####Summary####\n",
    "            output_line = output_line_template.format(epoch_ind = epoch_ind,\n",
    "                                                      ndcg_mean = ndcg_,\n",
    "                                                      ndcg_se='%.3f' % ndcg_serr,\n",
    "                                                      batch_loss='%6.3f' % avg_loss_dataset) \n",
    "            print(output_line)\n",
    "            sys.stdout.flush()\n",
    "            fw.write(output_line + '\\n')\n",
    "            summary_str = sess.run(summary, feed_dict={avg_loss_summary_ph : avg_loss_dataset,\n",
    "                                                       ndcg_summary_ph : ndcg_})\n",
    "            summary_writer.add_summary(summary_str, epoch_ind)\n",
    "            summary_writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(cold_start_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_video_level_metric_analysis(experiment_name,\n",
    "                                    EXP_DIR,\n",
    "                                    heldout_idxlist,\n",
    "                                    heldout_data_te,\n",
    "                                    heldout_start_index,\n",
    "                                    model_censored,\n",
    "                                    model_user_tags,\n",
    "                                    model_video_tags):\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Graph().as_default():\n",
    "        model1 = Model1(num_users,\n",
    "                    num_items,\n",
    "                    num_tags,\n",
    "                    num_factors,\n",
    "                    var_prior,\n",
    "                    video_metadata_array,\n",
    "                    availability,\n",
    "                    model_censored,\n",
    "                    model_user_tags,\n",
    "                    model_video_tags)\n",
    "        batch_logits, batch_logits_validation, log_softmax, avg_loss, batch_conditional_log_likelihood,\\\n",
    "        batch_kl_div, num_items_per_document = model1.construct_graph()\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        with tf.Session(config=config) as sess:\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(sess, os.path.join(EXP_DIR, 'tensorflow_models', experiment_name, 'files'))\n",
    "\n",
    "            ### Metrics computation ###\n",
    "            positives_list = []\n",
    "            positives_ranks_list = []\n",
    "            ndcg_dist = []\n",
    "            for batch_ind, st_index in enumerate(range(0, heldout_idxlist.shape[0], batch_size)):\n",
    "                end_index = min(st_index + batch_size, heldout_idxlist.shape[0])\n",
    "                heldout_user_indices = heldout_idxlist[st_index:end_index]\n",
    "                logit_validation = sess.run(batch_logits_validation,\n",
    "                                            feed_dict={model1.users_ph : heldout_user_indices})\n",
    "                X = all_tr_mat[heldout_user_indices]\n",
    "                X = X.toarray()\n",
    "                X = X.astype('float32')\n",
    "                labels = heldout_data_te[heldout_user_indices - heldout_start_index].toarray()\n",
    "                logit_validation[X.nonzero()] = -np.inf\n",
    "\n",
    "                ranking = np.argsort(-logit_validation, axis = 1)\n",
    "                videos_with_ranks = np.zeros(ranking.shape, dtype=np.int32)\n",
    "                videos_with_ranks[np.arange(logit_validation.shape[0])[:, np.newaxis], ranking] =\\\n",
    "                np.zeros(ranking.shape, dtype=np.int32) + np.arange(num_items)\n",
    "                rows, positives = np.where(labels)\n",
    "                ranks_of_positives = videos_with_ranks[rows, positives]\n",
    "                positives_list.append(positives)\n",
    "                positives_ranks_list.append(ranks_of_positives)\n",
    "                ndcg_dist.append(NDCG_binary_at_k_batch(logit_validation,\n",
    "                                                        heldout_data_te[heldout_user_indices - heldout_start_index]))\n",
    "            all_positives = np.concatenate(positives_list)\n",
    "            all_positives_ranks = np.concatenate(positives_ranks_list)\n",
    "            ndcg_dist = np.concatenate(ndcg_dist)\n",
    "            ndcg_ = ndcg_dist.mean()\n",
    "            ndcg_serr = ndcg_dist.std() / np.sqrt(ndcg_dist.shape[0])\n",
    "            print(ndcg_, '+/-', ndcg_serr)\n",
    "            video_ranks_df = pd.DataFrame({'sid' : all_positives, 'ranks' : all_positives_ranks})\n",
    "            video_ranks_df['mrr'] = 1.0 / (video_ranks_df['ranks'] + 1.0)\n",
    "            video_playcount_df = train_df.groupby('sid').apply(len).reset_index()\n",
    "            video_playcount_df.columns = ['sid', 'playcount']\n",
    "            video_avg_mrr_df = video_ranks_df.groupby('sid')['ranks', 'mrr'].mean().reset_index()\n",
    "            video_playcount_mrr_sorted_df =\\\n",
    "            pd.merge(video_playcount_df, video_avg_mrr_df, on = 'sid').sort_values(by = 'playcount', ascending = False)\n",
    "            return video_playcount_mrr_sorted_df, video_ranks_df, ndcg_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_playcount_mrr_sorted_withtags_df,video_ranks_withtags_df ,ndcg_withtags_dist =\\\n",
    "run_video_level_metric_analysis('censored-testmetrics-user=id-video=id_genreyear-learningrate=0.004-regularization=1e-09-numfactors=100-prior_var-1.0-epochs-1000-attempt=2',\n",
    "                                '/data/ml20m/ml-20m/exp',\n",
    "                                heldout_idxlist,\n",
    "                                heldout_data_te,\n",
    "                                heldout_start_index,\n",
    "                                model_censored=True,\n",
    "                                model_user_tags=False,\n",
    "                                model_video_tags =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_playcount_mrr_sorted_withouttags_df, video_ranks_withouttags_df, ndcg_withouttags_dist =\\\n",
    "run_video_level_metric_analysis('censored-testmetrics-user=id-video=id-learningrate=0.004-regularization=1e-09-numfactors=100-prior_var-1.0-epochs-1000-attempt=2',\n",
    "                               '/data/ml20m/ml-20m/exp',\n",
    "                                heldout_idxlist,\n",
    "                                heldout_data_te,\n",
    "                                heldout_start_index,\n",
    "                                model_censored=True,\n",
    "                                model_user_tags=False,\n",
    "                                model_video_tags =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_playcount_mrr_sorted_with_uv_tags_df,video_ranks_with_uv_tags_df ,ndcg_with_uv_tags_dist =\\\n",
    "run_video_level_metric_analysis(experiment_name=experiment_name,\n",
    "                                EXP_DIR=EXP_DIR,\n",
    "                                heldout_idxlist=heldout_idxlist,\n",
    "                                heldout_data_te=heldout_data_te,\n",
    "                                heldout_start_index=heldout_start_index,\n",
    "                                model_censored=True,\n",
    "                                model_user_tags=True,\n",
    "                                model_video_tags =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_playcount_mrr_sorted_withtags_df['label'] = 'with document tags'\n",
    "video_playcount_mrr_sorted_withouttags_df['label'] = 'without tags'\n",
    "video_playcount_mrr_sorted_with_uv_tags_df['label'] = 'with user, document tags'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = video_playcount_mrr_sorted_withtags_df['playcount'].quantile(np.linspace(0, 1, 5)).values.astype(np.int32)\n",
    "num_plays_ranks =\\\n",
    "np.argmax(video_playcount_mrr_sorted_withtags_df['playcount'][:, np.newaxis] <= levels, axis = 1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_playcount_mrr_sorted_withtags_df['rank'] = num_plays_ranks\n",
    "video_playcount_mrr_sorted_withouttags_df['rank'] = num_plays_ranks\n",
    "video_playcount_mrr_sorted_with_uv_tags_df['rank'] = num_plays_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_playcount_mrr_df = pd.concat([video_playcount_mrr_sorted_withouttags_df,\n",
    "                                    video_playcount_mrr_sorted_withtags_df,\n",
    "                                    video_playcount_mrr_sorted_with_uv_tags_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_playcount_mrr_df = pd.merge(video_playcount_mrr_df, availability_df, on = 'sid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_playcount_mrr_df.groupby(['availability', 'rank', 'label'])['ranks'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_playcount_mrr_df.groupby(['availability', 'label'])['ranks'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(figsize=(10, 8))\n",
    "ax = sns.barplot(x=\"availability\", y=\"ranks\", hue = 'label', data=video_playcount_mrr_df)\n",
    "ax.set_xlabel('Available');\n",
    "ax.set_ylabel('Average Rank');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_censored, model_user_tags, model_video_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    model1 = Model1(num_users,\n",
    "                num_items,\n",
    "                num_tags,\n",
    "                num_factors,\n",
    "                var_prior,\n",
    "                video_metadata_array,\n",
    "                availability,\n",
    "                model_censored,\n",
    "                model_user_tags,\n",
    "                model_video_tags)\n",
    "    batch_logits, batch_logits_validation, log_softmax, avg_loss, batch_conditional_log_likelihood,\\\n",
    "    batch_kl_div, num_items_per_document = model1.construct_graph()\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, os.path.join(EXP_DIR, 'tensorflow_models', experiment_name, 'files'))\n",
    "        logit_validation = sess.run(batch_logits_validation,\n",
    "                                    feed_dict={model1.users_ph : [0,1,2]})\n",
    "        print(logit_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.played_tags_ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
